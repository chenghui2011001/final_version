#!/usr/bin/env python3
"""
ç¦»çº¿æå–StableCodec latentè„šæœ¬

ä½¿ç”¨ç‹¬ç«‹ç¯å¢ƒè¿è¡Œï¼Œä¸ºJSCCè®­ç»ƒæä¾›teacher latent
é€‚é…data_expert_augmented_small200kæ•°æ®é›†çš„PCMæ ¼å¼

ä½¿ç”¨æ–¹æ³•:
    conda activate stablecodec-offline  # æ¿€æ´»ç‹¬ç«‹ç¯å¢ƒ
    python scripts/extract_stablecodec_latents.py --data-root ./data_expert_augmented_small200k --output-dir ./teacher_latents
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple
import warnings
import time

import torch
import torchaudio
import numpy as np
from tqdm import tqdm


def setup_imports():
    """è®¾ç½®StableCodecå¯¼å…¥"""
    try:
        from stable_codec.model import StableCodec
        return StableCodec
    except ImportError as e:
        print(f"âŒ StableCodecå¯¼å…¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿åœ¨stablecodec-offlineç¯å¢ƒä¸­è¿è¡Œ:")
        print("  conda activate stablecodec-offline")
        print("  python scripts/extract_stablecodec_latents.py ...")
        sys.exit(1)


def load_pcm_file(pcm_path: Path, sample_rate: int = 16000) -> torch.Tensor:
    """
    åŠ è½½PCMæ–‡ä»¶ä¸ºtorch tensor

    Args:
        pcm_path: PCMæ–‡ä»¶è·¯å¾„
        sample_rate: é‡‡æ ·ç‡

    Returns:
        audio: [T] float32 tensor, normalized to [-1,1]
    """
    # PCMæ–‡ä»¶æ˜¯raw 16-bit signed integer
    with open(pcm_path, 'rb') as f:
        raw_data = f.read()

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    audio_int16 = np.frombuffer(raw_data, dtype=np.int16)

    # å½’ä¸€åŒ–åˆ°[-1,1]
    audio_float = audio_int16.astype(np.float32) / 32768.0

    # è½¬ä¸ºtorch tensor
    audio_tensor = torch.from_numpy(audio_float)

    return audio_tensor


def generate_audio_key(pcm_path: Path, data_root: Path) -> str:
    """
    ç”Ÿæˆç»Ÿä¸€çš„audio_key

    ä¾‹å­:
        pcm_path: /path/to/data_expert_augmented_small200k/harmonic_200k.pcm
        data_root: /path/to/data_expert_augmented_small200k
        -> audio_key: "harmonic_200k"
    """
    rel_path = pcm_path.relative_to(data_root)
    audio_key = str(rel_path.with_suffix(''))  # å»æ‰.pcmæ‰©å±•å
    return audio_key


def find_pcm_files(data_root: Path) -> List[Path]:
    """æŸ¥æ‰¾æ‰€æœ‰PCMæ–‡ä»¶ï¼ˆé€’å½’ï¼‰"""
    pcm_files = list(data_root.rglob("*.pcm"))
    pcm_files.sort()
    return pcm_files


def estimate_frames_and_duration(audio_tensor: torch.Tensor, sample_rate: int) -> Tuple[int, int, float]:
    """
    ä¼°è®¡StableCodec latentçš„å‚æ•°

    Returns:
        audio_samples: éŸ³é¢‘æ ·æœ¬æ•°
        estimated_frames: ä¼°è®¡çš„StableCodecå¸§æ•° (~25Hz)
        duration_sec: æ—¶é•¿(ç§’)
    """
    audio_samples = audio_tensor.size(0)
    duration_sec = audio_samples / sample_rate

    # StableCodecçº¦25Hzå¸§ç‡
    stablecodec_frame_rate = 25.0
    estimated_frames = int(duration_sec * stablecodec_frame_rate)

    return audio_samples, estimated_frames, duration_sec


def upsample_to_fargan_rate(latent_25hz: torch.Tensor, fargan_rate: float = 100.0) -> torch.Tensor:
    """
    å°†25Hz latentä¸Šé‡‡æ ·åˆ°FARGANå¸§ç‡(100Hz)

    Args:
        latent_25hz: [T_25hz, D] StableCodec latent at ~25Hz
        fargan_rate: FARGANå¸§ç‡

    Returns:
        latent_100hz: [T_100hz, D] ä¸Šé‡‡æ ·åçš„latent
    """
    if latent_25hz.size(0) <= 1:
        return latent_25hz

    # è®¡ç®—ä¸Šé‡‡æ ·å€æ•°
    scale_factor = fargan_rate / 25.0  # é€šå¸¸æ˜¯4å€

    # [T_25hz, D] -> [1, D, T_25hz] -> interpolate -> [1, D, T_100hz] -> [T_100hz, D]
    latent_1dt = latent_25hz.transpose(0, 1).unsqueeze(0)  # [1, D, T_25hz]

    latent_up_1dt = torch.nn.functional.interpolate(
        latent_1dt,
        scale_factor=scale_factor,
        mode='linear',
        align_corners=False
    )

    latent_100hz = latent_up_1dt.squeeze(0).transpose(0, 1)  # [T_100hz, D]

    return latent_100hz


def extract_latents_for_pcm(pcm_path: Path,
                           stablecodec_model,
                           data_root: Path,
                           output_dir: Path,
                           upsample_to_fargan: bool = True,
                           fargan_rate: float = 100.0) -> Dict:
    """
    ä¸ºå•ä¸ªPCMæ–‡ä»¶æå–StableCodec latent

    Returns:
        ç»“æœå­—å…¸åŒ…å«ç»Ÿè®¡ä¿¡æ¯
    """
    audio_key = generate_audio_key(pcm_path, data_root)
    output_path = output_dir / f"{audio_key}.pt"

    # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
    if output_path.exists():
        return {"status": "skipped", "audio_key": audio_key}

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        # åŠ è½½éŸ³é¢‘
        audio_tensor = load_pcm_file(pcm_path, sample_rate=16000)
        audio_samples, est_frames, duration = estimate_frames_and_duration(audio_tensor, 16000)

        # ä¸ºStableCodecå‡†å¤‡è¾“å…¥ [1, 1, T]
        dev = next(stablecodec_model.parameters()).device
        audio_batch = audio_tensor.unsqueeze(0).unsqueeze(0).to(dev)

        # æå–latent
        with torch.no_grad():
            # StableCodec.encodeè¿”å› (pre_bottleneck_latents, tokens)
            # pre_bottleneck_latents: [B, H, S] where S is ~25Hz frames
            pre_latents, _tokens = stablecodec_model.encode(audio_batch, posthoc_bottleneck=False)

            # [B, H, S] -> [S, H] (å»æ‰batchç»´åº¦å¹¶è½¬ç½®)
            latent_25hz = pre_latents.squeeze(0).transpose(0, 1).contiguous()  # [S, H]

        # å¯é€‰ï¼šä¸Šé‡‡æ ·åˆ°FARGANå¸§ç‡
        if upsample_to_fargan:
            latent_final = upsample_to_fargan_rate(latent_25hz, fargan_rate)
            frame_info = f"25Hz({latent_25hz.size(0)}) -> {fargan_rate}Hz({latent_final.size(0)})"
        else:
            latent_final = latent_25hz
            frame_info = f"25Hz({latent_final.size(0)})"

        # ä¿å­˜åˆ°ç£ç›˜
        torch.save(latent_final.cpu(), output_path)

        return {
            "status": "success",
            "audio_key": audio_key,
            "duration_sec": duration,
            "audio_samples": audio_samples,
            "latent_shape": list(latent_final.shape),
            "frame_info": frame_info,
            "output_path": str(output_path)
        }

    except Exception as e:
        return {
            "status": "error",
            "audio_key": audio_key,
            "error": str(e)
        }


def main():
    parser = argparse.ArgumentParser(description="ç¦»çº¿æå–StableCodec teacher latents")
    parser.add_argument("--data-root", type=str, required=True,
                      help="æ•°æ®é›†æ ¹ç›®å½• (e.g., ./data_expert_augmented_small200k)")
    parser.add_argument("--output-dir", type=str, required=True,
                      help="è¾“å‡ºlatentç›®å½• (e.g., ./teacher_latents)")
    parser.add_argument("--pretrained-model", type=str,
                      default="stabilityai/stable-codec-speech-16k",
                      help="StableCodecé¢„è®­ç»ƒæ¨¡å‹")
    parser.add_argument("--upsample-to-fargan", action="store_true", default=True,
                      help="æ˜¯å¦ä¸Šé‡‡æ ·åˆ°FARGANå¸§ç‡(100Hz) (å½“å‰é»˜è®¤å¼€å¯)")
    parser.add_argument("--fargan-rate", type=float, default=100.0,
                      help="FARGANå¸§ç‡(Hz)")
    parser.add_argument("--device", type=str, default="auto",
                      help="è®¡ç®—è®¾å¤‡ (cuda/cpu/auto)")

    args = parser.parse_args()

    # è®¾ç½®è®¾å¤‡
    if args.device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(args.device)

    print(f"ğŸš€ StableCodec Latentæå–å™¨")
    print(f"ğŸ“‚ æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“± è®¾å¤‡: {device}")
    print(f"ğŸµ ç›®æ ‡å¸§ç‡: {args.fargan_rate}Hz (ä¸Šé‡‡æ ·: {args.upsample_to_fargan})")

    # å¯¼å…¥StableCodec
    StableCodec = setup_imports()

    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_root = Path(args.data_root)
    if not data_root.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        sys.exit(1)

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # æŸ¥æ‰¾PCMæ–‡ä»¶
    pcm_files = find_pcm_files(data_root)
    if not pcm_files:
        print(f"âŒ åœ¨ {data_root} ä¸­æœªæ‰¾åˆ°PCMæ–‡ä»¶")
        sys.exit(1)

    print(f"ğŸ“Š æ‰¾åˆ° {len(pcm_files)} ä¸ªPCMæ–‡ä»¶:")
    for pcm in pcm_files:
        print(f"  - {pcm.name}")

    # åŠ è½½StableCodecæ¨¡å‹
    print(f"ğŸ”§ åŠ è½½StableCodecæ¨¡å‹: {args.pretrained_model}")
    try:
        stablecodec = StableCodec(
            pretrained_model=args.pretrained_model,
            device=device
        )
        stablecodec.eval().requires_grad_(False)
        print(f"âœ… StableCodecåŠ è½½æˆåŠŸ! é‡‡æ ·ç‡: {stablecodec.sample_rate}Hz")
    except Exception as e:
        print(f"âŒ StableCodecåŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

    # å¤„ç†æ¯ä¸ªPCMæ–‡ä»¶
    print(f"ğŸ”„ å¼€å§‹æå–latents...")
    results = []
    start_time = time.time()

    for pcm_path in tqdm(pcm_files, desc="æå–latents"):
        result = extract_latents_for_pcm(
            pcm_path=pcm_path,
            stablecodec_model=stablecodec,
            data_root=data_root,
            output_dir=output_dir,
            upsample_to_fargan=args.upsample_to_fargan,
            fargan_rate=args.fargan_rate
        )
        results.append(result)

        # æ‰“å°è¿›åº¦
        if result["status"] == "success":
            tqdm.write(f"âœ… {result['audio_key']}: {result['frame_info']}, "
                      f"{result['duration_sec']:.1f}s")
        elif result["status"] == "error":
            tqdm.write(f"âŒ {result['audio_key']}: {result['error']}")
        else:  # skipped
            tqdm.write(f"â­ï¸  {result['audio_key']}: å·²å­˜åœ¨")

    # ç»Ÿè®¡ç»“æœ
    total_time = time.time() - start_time
    success_count = sum(1 for r in results if r["status"] == "success")
    error_count = sum(1 for r in results if r["status"] == "error")
    skip_count = sum(1 for r in results if r["status"] == "skipped")

    print(f"\nğŸ“Š æå–å®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"â­ï¸  è·³è¿‡: {skip_count}")
    print(f"âŒ å¤±è´¥: {error_count}")

    if error_count > 0:
        print(f"\nâŒ å¤±è´¥è¯¦æƒ…:")
        for r in results:
            if r["status"] == "error":
                print(f"  {r['audio_key']}: {r['error']}")

    # ä¿å­˜æå–æ—¥å¿—
    log_path = output_dir / "extraction_log.txt"
    with open(log_path, 'w') as f:
        f.write(f"StableCodec Latentæå–æ—¥å¿—\n")
        f.write(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ•°æ®æ ¹ç›®å½•: {args.data_root}\n")
        f.write(f"è¾“å‡ºç›®å½•: {args.output_dir}\n")
        f.write(f"è®¾å¤‡: {device}\n")
        f.write(f"ä¸Šé‡‡æ ·åˆ°FARGAN: {args.upsample_to_fargan} ({args.fargan_rate}Hz)\n")
        f.write(f"æ€»æ–‡ä»¶æ•°: {len(pcm_files)}\n")
        f.write(f"æˆåŠŸ: {success_count}, è·³è¿‡: {skip_count}, å¤±è´¥: {error_count}\n")
        f.write(f"æ€»è€—æ—¶: {total_time:.1f}ç§’\n\n")

        f.write("è¯¦ç»†ç»“æœ:\n")
        for r in results:
            f.write(f"{r}\n")

    print(f"ğŸ“ æå–æ—¥å¿—å·²ä¿å­˜: {log_path}")


if __name__ == "__main__":
    main()
