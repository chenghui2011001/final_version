# -*- coding: utf-8 -*-
"""
AETHER-FARGANæ··åˆè§£ç å™¨
ç»“åˆAETHERçš„å¼ºå¤§ç¼–ç èƒ½åŠ›ä¸FARGANçš„ä¼˜ç§€æ³¢å½¢ç”Ÿæˆèƒ½åŠ›
ç»§æ‰¿å¹¶æ‰©å±•åŸå§‹AETHERDecoderæ¶æ„
"""

from __future__ import annotations
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, Optional, Any
import math

try:
    # Prefer package-relative imports
    from ..aether_encoder_decoder import AETHERDecoder
    from ..feature_adapter import Feature48To36Adapter, FARGANFeatureSpec
    from ..fargan_components import FARGANCore
except Exception:
    # Fallback to absolute package imports if run with sys.path adjusted
    from models.aether_encoder_decoder import AETHERDecoder
    from models.feature_adapter import Feature48To36Adapter, FARGANFeatureSpec
    from models.fargan_components import FARGANCore

try:
    # Prefer top-level 'utils' namespace under final_version
    from utils.feature_spec import get_default_feature_spec
except Exception:
    # Fallback to fully qualified import if package layout is present
    from dnn.torch.final_version.utils.feature_spec import get_default_feature_spec


class PeriodEstimator(nn.Module):
    """ä»FARGANç‰¹å¾ä¼°è®¡å‘¨æœŸåºåˆ—"""

    def __init__(self):
        super().__init__()
        self.period_proj = nn.Sequential(
            nn.Linear(20, 32),  # åªç”¨å‰20ç»´ç‰¹å¾
            nn.GELU(),
            nn.Linear(32, 1)
        )

    def forward(self, fargan_features: torch.Tensor) -> torch.Tensor:
        """
        ä»FARGANç‰¹å¾ä¼°è®¡å‘¨æœŸ

        Args:
            fargan_features: [B, T, 36] FARGANç‰¹å¾

        Returns:
            period: [B, T] å‘¨æœŸåºåˆ— (32-255)
        """
        # Stage3ä¸€è‡´çš„æ˜ å°„ï¼šç”± dnn_pitch â†’ f0_hz â†’ period
        # è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨ï¼šf0_hz = sr * 2**(dnn_pitch - 6.5)ï¼Œå† period = round(16000/f0)
        dnn_pitch = fargan_features[..., 18:19]  # [B, T, 1]
        f0_hz = (16000.0 * torch.pow(2.0, dnn_pitch - 6.5)).clamp(50.0, 400.0)
        period_raw = (16000.0 / f0_hz).clamp(32.0, 255.0)
        period = torch.round(period_raw).to(torch.long).squeeze(-1)

        return period


class AETHERFARGANDecoder(AETHERDecoder):
    """AETHER-FARGANæ··åˆè§£ç å™¨

    ç»§æ‰¿AETHERDecoderï¼Œç›´æ¥å·¥ä½œåœ¨36-dim FARGANç‰¹å¾åŸŸ
    ç§»é™¤ç‰¹å¾é€‚é…å™¨ï¼Œç®€åŒ–æ¶æ„
    """

    def __init__(
        self,
        dz: int = 24,
        d_out: int = 36,  # ç›´æ¥è¾“å‡º36ç»´FARGANç‰¹å¾
        d_hidden: int = 128,
        d_csi: int = 32,
        decoder_heads: int = 2,
        enable_synth: bool = True,  # é»˜è®¤å¯ç”¨FARGANåˆæˆ
        fargan_subframe_size: int = 40,
        fargan_nb_subframes: int = 4,
        frame_rate_hz: float = 100.0,
        feature_spec_type: str = "fargan",
        use_film: bool = False,
        enable_output_calibration: bool = False,
        enable_ceps_affine_calib: bool = True,
    ):
        # åˆå§‹åŒ–çˆ¶ç±»AETHERDecoderï¼Œç›´æ¥ä½¿ç”¨FARGANç‰¹å¾è§„èŒƒ
        super().__init__(
            dz=dz,
            d_out=d_out,
            d_hidden=d_hidden,
            d_csi=d_csi,
            decoder_heads=decoder_heads,
            enable_synth=False,  # ç¦ç”¨åŸæœ‰çš„OLAåˆæˆå™¨
            feature_spec_type=feature_spec_type,
            use_film=use_film,
        )

        # FARGANä¸“ç”¨å‚æ•°
        self.enable_fargan_synth = enable_synth
        self.frame_rate_hz = frame_rate_hz
        self.fargan_frame_size = fargan_subframe_size * fargan_nb_subframes  # 160
        self.enable_output_calibration = bool(enable_output_calibration)
        self.enable_ceps_affine_calib = bool(enable_ceps_affine_calib)

        # é€ç»´ä»¿å°„æ ¡å‡†ï¼ˆä»…ä½œç”¨äº ceps[0..17]ï¼‰ï¼Œè®­ç»ƒ/æ¨ç†ä¸€è‡´
        if self.enable_ceps_affine_calib:
            self.register_parameter('ceps_gamma', nn.Parameter(torch.ones(18)))
            self.register_parameter('ceps_beta', nn.Parameter(torch.zeros(18)))
        else:
            self.register_parameter('ceps_gamma', nn.Parameter(torch.ones(18), requires_grad=False))
            self.register_parameter('ceps_beta', nn.Parameter(torch.zeros(18), requires_grad=False))

        # å¯é€‰ï¼šå¯¹å®Œæ•´36ç»´ç‰¹å¾åšä»¿å°„æ ¡å‡†ï¼ˆè§£ç ç«¯â€œå»ç™½åŒ–/æ ‡å®šâ€ï¼‰
        if self.enable_output_calibration:
            self.register_parameter('feat_gamma_36', nn.Parameter(torch.ones(36)))
            self.register_parameter('feat_beta_36', nn.Parameter(torch.zeros(36)))
        else:
            self.register_parameter('feat_gamma_36', nn.Parameter(torch.ones(36), requires_grad=False))
            self.register_parameter('feat_beta_36', nn.Parameter(torch.zeros(36), requires_grad=False))

        # å‘¨æœŸä¼°è®¡å™¨
        self.period_estimator = PeriodEstimator()

        # è½»é‡å‘¨æœŸå¹³æ»‘ä»¥æŠ‘åˆ¶èœ‚é¸£/å—¡å—¡ä¼ªå½±ï¼ˆé»˜è®¤å¯ç”¨3å¸§ä¸­å€¼ï¼‰
        self.period_smooth_ks: int = 3     # å¥‡æ•°ï¼Œ>=1ï¼›1 è¡¨ç¤ºä¸å¹³æ»‘
        self.period_smooth_mode: str = 'median'  # 'median' æˆ– 'mean'

        # FARGANæ ¸å¿ƒåˆæˆå™¨
        if enable_synth:
            self.fargan_core = FARGANCore(
                subframe_size=fargan_subframe_size,
                nb_subframes=fargan_nb_subframes,
                feature_dim=20,  # ä½¿ç”¨å‰20ç»´ç‰¹å¾
                cond_size=256
            )

        print(f"ğŸš€ AETHER-FARGANè§£ç å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - åŸºç¡€æ¶æ„: AETHERDecoder (GLABlock + ConvRefineDecoder)")
        print(f"   - æ½œåœ¨ç»´åº¦: {dz}")
        print(f"   - è¾“å‡ºç»´åº¦: {d_out} (FARGANç‰¹å¾)")
        print(f"   - ç‰¹å¾è§„èŒƒ: {feature_spec_type}")
        print(f"   - FARGANåˆæˆ: {'å¯ç”¨' if enable_synth else 'ç¦ç”¨'}")
        print(f"   - å¸§ç‡: {frame_rate_hz} Hz")
        print(f"   - FARGANå¸§å¤§å°: {self.fargan_frame_size} æ ·æœ¬")

        # --- Decoder-side Residual MoE (token-level Top-K) ---
        self.enable_dec_moe: bool = True
        self.dec_moe = DecoderResidualMoE(d_in=d_out, hidden=64, n_experts=3, top_k=2)

    def _forward_features(
        self,
        z: torch.Tensor,
        csi_dict: Dict[str, torch.Tensor],
        attn_mask: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­ï¼Œç›´æ¥è¾“å‡º36ç»´FARGANç‰¹å¾

        Returns:
            fargan_features: [B, T, 36] FARGANç‰¹å¾
        """
        # ç›´æ¥ä½¿ç”¨çˆ¶ç±»æ–¹æ³•ï¼Œç°åœ¨å·²ç»é…ç½®ä¸ºè¾“å‡º36ç»´ç‰¹å¾
        fargan_features = super()._forward_features(z, csi_dict, attn_mask)
        # å…¨ç»´ä»¿å°„æ ¡å‡†ï¼ˆå…ˆæ•´ä½“å†å¯¹cepså­æ®µç»†åŒ–ï¼‰
        try:
            if self.enable_output_calibration:
                gamma36 = self.feat_gamma_36.to(fargan_features.device, fargan_features.dtype).view(1, 1, -1)
                beta36 = self.feat_beta_36.to(fargan_features.device, fargan_features.dtype).view(1, 1, -1)
                fargan_features = fargan_features * gamma36 + beta36
        except Exception:
            pass
        return fargan_features

    def _estimate_period(self, fargan_features: torch.Tensor) -> torch.Tensor:
        """
        ä»FARGANç‰¹å¾ä¼°è®¡å‘¨æœŸ

        Args:
            fargan_features: [B, T, 36] FARGANç‰¹å¾

        Returns:
            period: [B, T] å‘¨æœŸåºåˆ—
        """
        period = self.period_estimator(fargan_features)
        return period

    def _generate_waveform(
        self,
        fargan_features: torch.Tensor,
        period: torch.Tensor,
        target_len: Optional[int] = None,
        fargan_pre: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        ä½¿ç”¨FARGANæ ¸å¿ƒç”Ÿæˆæ³¢å½¢

        Args:
            fargan_features: [B, T, 36] FARGANç‰¹å¾
            period: [B, T] å‘¨æœŸåºåˆ—
            target_len: ç›®æ ‡éŸ³é¢‘é•¿åº¦
            fargan_pre: [B, 1, L] å¯é€‰çš„å‰åºéŸ³é¢‘ï¼Œç”¨äºteacher forcing

        Returns:
            audio: [B, 1, L] ç”Ÿæˆçš„éŸ³é¢‘æ³¢å½¢
        """
        if not self.enable_fargan_synth:
            raise RuntimeError("FARGANåˆæˆå™¨æœªå¯ç”¨")

        B, T, _ = fargan_features.shape

        # è®¡ç®—éœ€è¦ç”Ÿæˆçš„å¸§æ•°ï¼ˆä¸¥æ ¼å¯¹é½ models/fargan_decoder.py çš„é€»è¾‘ï¼‰
        # æ¡ä»¶ç½‘ç»œæ—¶é—´ç»´æ”¶ç¼©ï¼šT -> T-4ï¼Œå¯ç”¨å¸§æ•° = T-4ã€‚
        max_available_frames = T - 4
        # æ•™å¸ˆå¼ºåˆ¶é¢„çƒ­å¸§æ•°ï¼ˆè‹¥æä¾›preï¼‰ï¼Œæ³¨æ„ FARGANCore é‡Œä¼šåœ¨å‰ nb_pre_frames æ­¥ç›´æ¥ä½¿ç”¨preï¼Œä¸è®¡å…¥è¾“å‡º
        nb_pre_frames = 0
        pre = fargan_pre
        if pre is not None:
            if pre.dim() == 3:  # [B,1,L] -> [B,L]
                pre = pre.squeeze(1)
            nb_pre_frames = pre.size(1) // self.fargan_frame_size

        gen_capacity = max(0, max_available_frames - nb_pre_frames)
        if target_len is not None:
            target_frames_total = (target_len + self.fargan_frame_size - 1) // self.fargan_frame_size
            target_frames_gen = max(0, target_frames_total - nb_pre_frames)
            nb_frames = min(gen_capacity, target_frames_gen)
        else:
            nb_frames = gen_capacity

        # è‡³å°‘ç”Ÿæˆ1å¸§
        nb_frames = max(1, nb_frames)

        # è½»é‡æ—¶é—´å¹³æ»‘å‘¨æœŸï¼ŒæŠ‘åˆ¶å°‘é‡å¸§æŠ–åŠ¨å¯¼è‡´çš„çª„å¸¦ä¼ªå½±
        try:
            ks = int(getattr(self, 'period_smooth_ks', 1) or 1)
            mode = str(getattr(self, 'period_smooth_mode', 'median') or 'median')
            if ks > 1 and ks % 2 == 1 and period.dim() == 2:
                import torch.nn.functional as F
                pad = (ks - 1) // 2
                p = period.to(torch.float32)
                p = F.pad(p.unsqueeze(1), (pad, pad), mode='replicate').squeeze(1)  # [B, T+2pad]
                win = p.unfold(dimension=1, size=ks, step=1)                         # [B, T, ks]
                if mode == 'mean':
                    ps = win.mean(dim=-1)
                else:
                    ps, _ = win.median(dim=-1)
                period = ps.round().clamp(32, 255).to(torch.long)
        except Exception:
            pass

        # ä½¿ç”¨å‰20ç»´ç‰¹å¾è¿›è¡ŒFARGANåˆæˆ
        features_20 = fargan_features[..., :20]

        # FARGANç”Ÿæˆ (æ”¯æŒteacher forcing)
        audio, _ = self.fargan_core(features_20, period, nb_frames, pre=pre)

        # ç¡®ä¿è¾“å‡ºå½¢çŠ¶ä¸º [B, 1, L]
        if audio.dim() == 2:
            audio = audio.unsqueeze(1)

        # è£å‰ªåˆ°ç›®æ ‡é•¿åº¦
        if target_len is not None and audio.size(-1) > target_len:
            audio = audio[..., :target_len]

        return audio

    def forward(
        self,
        z: torch.Tensor,
        csi_dict: Dict[str, torch.Tensor],
        attn_mask: Optional[torch.Tensor] = None,
        return_wave: bool = False,
        target_len: Optional[int] = None
    ):
        """
        å‰å‘ä¼ æ’­ï¼Œä¿æŒä¸AETHERDecoderå…¼å®¹çš„æ¥å£

        Args:
            z: [B, T, dz] æ½œåœ¨è¡¨ç¤º
            csi_dict: CSIå­—å…¸
            attn_mask: æ³¨æ„åŠ›æ©ç 
            return_wave: æ˜¯å¦è¿”å›æ³¢å½¢
            target_len: ç›®æ ‡éŸ³é¢‘é•¿åº¦

        Returns:
            å¦‚æœreturn_wave=False: fargan_features [B, T, 36]
            å¦‚æœreturn_wave=True: (fargan_features [B, T, 36], audio [B, 1, L])
        """
        # æ­¥éª¤1: ç›´æ¥é‡å»º36ç»´FARGANç‰¹å¾
        fargan_features = super()._forward_features(z, csi_dict, attn_mask)
        # ç¼“å­˜æ ¡å‡†å‰åŸå§‹è¾“å‡ºï¼Œä¾›æŸå¤±åœ¨rawç©ºé—´è¿›è¡Œç»Ÿè®¡
        try:
            self._last_raw_features = fargan_features.detach()
        except Exception:
            self._last_raw_features = None
        # ç¼“å­˜ç¬¬0ç»´ç‰¹å¾åˆ†å¸ƒï¼ˆä¾›è®­ç»ƒè„šæœ¬è¿­ä»£æ‰“å°ï¼‰
        try:
            feat0 = fargan_features[..., 0]
            self._last_feat0_stats = {
                'mean': float(feat0.mean().detach().cpu().item()),
                'std':  float(feat0.std().detach().cpu().item()),
                'min':  float(feat0.min().detach().cpu().item()),
                'max':  float(feat0.max().detach().cpu().item()),
            }
        except Exception:
            pass

        # è®­ç»ƒ/æ¨ç†ä¸€è‡´çš„ ceps æ®µä»¿å°„æ ¡å‡†ï¼ˆåªä½œç”¨äºç‰¹å¾è¾“å‡ºï¼Œéåˆæˆä¸“ç”¨ï¼‰
        try:
            if self.enable_ceps_affine_calib:
                from models.feature_adapter import FARGANFeatureSpec
                ceps_slice = FARGANFeatureSpec.get_feature_slice('ceps')
                out_ceps = fargan_features[..., ceps_slice]
                # åº”ç”¨é€ç»´ä»¿å°„ï¼šy = gamma * x + beta
                gamma = self.ceps_gamma.to(out_ceps.device, out_ceps.dtype).view(1, 1, -1)
                beta = self.ceps_beta.to(out_ceps.device, out_ceps.dtype).view(1, 1, -1)
                out_ceps = out_ceps * gamma + beta
                fargan_features = fargan_features.clone()
                fargan_features[..., ceps_slice] = out_ceps
                # æ­£åˆ™åŒ–å€¼ç¼“å­˜ï¼ˆä¾›lossè¯»å–ï¼‰
                # è®°å½•æ•´ä½“ä¸cepsçš„æ­£åˆ™ï¼ˆæœ‰åŠ©äºæŸå¤±ç«¯è½»å¾®çº¦æŸï¼‰
                reg_ceps = (self.ceps_gamma - 1.0).pow(2).mean() + self.ceps_beta.pow(2).mean()
                try:
                    reg_full = (self.feat_gamma_36 - 1.0).pow(2).mean() + self.feat_beta_36.pow(2).mean()
                except Exception:
                    reg_full = torch.tensor(0.0, device=fargan_features.device)
                self._last_calib_reg = reg_full + reg_ceps
            else:
                self._last_calib_reg = None
        except Exception:
            self._last_calib_reg = None

        # å¯é€‰ï¼šè¾“å‡ºç«¯çº¿æ€§æ ¡å‡†ï¼ˆä»…ç”¨äºåˆæˆè·¯å¾„ï¼‰ï¼Œå°† ceps[0:18] æ ¡å‡†åˆ°ç›®æ ‡ batch ç»Ÿè®¡
        if self.enable_output_calibration and csi_dict is not None:
            try:
                from models.feature_adapter import FARGANFeatureSpec
                ceps_slice = FARGANFeatureSpec.get_feature_slice('ceps')
                tgt_mean = csi_dict.get('calib_ceps_mean', None)
                tgt_std = csi_dict.get('calib_ceps_std', None)
                if torch.is_tensor(tgt_mean) and torch.is_tensor(tgt_std):
                    # è®¡ç®—è¾“å‡º ceps çš„å½“å‰ç»Ÿè®¡
                    out_ceps = fargan_features[..., ceps_slice]  # [B,T,18]
                    mu = out_ceps.mean(dim=(0, 1))               # [18]
                    sd = out_ceps.std(dim=(0, 1)).clamp_min(1e-4)
                    # æ ‡å‡†åŒ–å†åŒ¹é…åˆ°ç›®æ ‡ batch
                    out_ceps_norm = (out_ceps - mu.view(1, 1, -1)) / sd.view(1, 1, -1)
                    out_ceps_cal = out_ceps_norm * tgt_std.view(1, 1, -1) + tgt_mean.view(1, 1, -1)
                    fargan_features = fargan_features.clone()
                    fargan_features[..., ceps_slice] = out_ceps_cal
                    # é¢å¤–ï¼šframe_corr å¤¹ç´§åˆ°è§„èŒƒèŒƒå›´
                    fc_slice = FARGANFeatureSpec.get_feature_slice('frame_corr')
                    fargan_features[..., fc_slice] = fargan_features[..., fc_slice].clamp(-0.8, 0.5)
                    # ç¼“å­˜æ ¡å‡†ç»Ÿè®¡
                    self._last_calib_stats = {
                        'out_mu': mu.detach().cpu().tolist(),
                        'out_sd': sd.detach().cpu().tolist(),
                        'tgt_mu': tgt_mean.detach().cpu().tolist(),
                        'tgt_sd': tgt_std.detach().cpu().tolist(),
                    }
            except Exception:
                pass

        # æ­¥éª¤1.5: æ®‹å·®MoEç»“æ„æ€§è¡¥å¿ï¼ˆå¯é€‰ï¼‰ã€‚å¦‚æœå¯ç”¨ï¼Œä¼ å…¥CSIå¹¶æ•è·è¾…åŠ©æ­£åˆ™lossã€‚
        if self.enable_dec_moe and self.dec_moe is not None:
            delta, aux = self.dec_moe(fargan_features, csi_dict=csi_dict, return_aux=True)
            # æš‚å­˜è¾…åŠ©losså’Œç»Ÿè®¡ï¼Œä¾›è®­ç»ƒå¾ªç¯è¯»å–å¹¶åŠ å…¥æ€»lossï¼ˆä¸æ”¹åŠ¨forwardè¿”å›ç­¾åï¼‰
            try:
                self._dec_moe_aux = aux
                self._dec_moe_aux_loss = aux.get('loss', None)
            except Exception:
                pass
            fargan_features = fargan_features + delta

        if not return_wave:
            # å¦‚æœä¸éœ€è¦æ³¢å½¢ï¼Œè¿”å›FARGANç‰¹å¾
            return fargan_features

        # æ­¥éª¤2: ä¼°è®¡å‘¨æœŸ
        period = self._estimate_period(fargan_features)

        # æ­¥éª¤3: ç”Ÿæˆæ³¢å½¢
        if self.enable_fargan_synth:
            # ä»csi_dictä¸­æå–fargan_preå‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            fargan_pre = csi_dict.get('fargan_pre') if csi_dict else None
            audio = self._generate_waveform(fargan_features, period, target_len, fargan_pre)
            # å°†FARGANæ ¸å¿ƒçš„æœ€è¿‘ä¸€æ¬¡å¢ç›Šç»Ÿè®¡ç¼“å­˜åˆ°decoder
            try:
                if hasattr(self, 'fargan_core') and hasattr(self.fargan_core, '_last_gain_stats'):
                    self._last_gain_stats = dict(self.fargan_core._last_gain_stats)
            except Exception:
                pass
            return fargan_features, audio
        else:
            # å¦‚æœFARGANåˆæˆå™¨æœªå¯ç”¨ï¼Œè¿”å›é›¶éŸ³é¢‘
            audio_len = target_len or (fargan_features.size(1) * self.fargan_frame_size)
            audio = torch.zeros(fargan_features.size(0), 1, audio_len,
                              device=fargan_features.device, dtype=fargan_features.dtype)
            return fargan_features, audio

    def get_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {
            'model_type': 'AETHER-FARGANæ··åˆè§£ç å™¨',
            'base_architecture': 'AETHERDecoder',
            'latent_dim': self.dz,
            'output_feature_dim': self.d_out,  # ç›´æ¥è¾“å‡º36ç»´FARGANç‰¹å¾
            'csi_dim': self.d_csi,
            'fargan_frame_size': self.fargan_frame_size,
            'frame_rate_hz': self.frame_rate_hz,
            'fargan_synth_enabled': self.enable_fargan_synth,
            'decoder_residual_moe': {
                'enabled': bool(self.enable_dec_moe),
                'n_experts': int(getattr(self.dec_moe, 'n_experts', 0)) if hasattr(self, 'dec_moe') else 0,
                'top_k': int(getattr(self.dec_moe, 'top_k', 0)) if hasattr(self, 'dec_moe') else 0,
            },
            'components': {
                'global_recompose': 'GLABlock (ç»§æ‰¿è‡ªAETHERDecoder)',
                'refiner': 'ConvRefineDecoder (ç»§æ‰¿è‡ªAETHERDecoder)',
                'period_estimator': 'PeriodEstimator',
                'fargan_core': 'FARGANCore' if self.enable_fargan_synth else None
            },
            'total_parameters': sum(p.numel() for p in self.parameters())
        }
        return info

    # æä¾›è®­ç»ƒç«¯ç”¨äºæ—¥å¿—çš„MoEç»Ÿè®¡
    def get_dec_moe_stats(self) -> Dict[str, Any]:
        if hasattr(self, 'dec_moe') and self.dec_moe is not None:
            return self.dec_moe.get_stats()
        return {}


class DecoderResidualMoE(nn.Module):
    """è§£ç ç«¯æ®‹å·®MoEï¼šåœ¨FARGAN 36ç»´ç‰¹å¾ä¸Šè¿›è¡Œç»“æ„æ€§è¡¥å¿ï¼ˆç¬æ€/ç¼ºå£/è°æ³¢/è°±ä¸ç¨³ï¼‰ã€‚

    - Token-level Top-K è·¯ç”±ï¼ˆé»˜è®¤K=2ï¼‰ï¼Œè·¯ç”±è¾“å…¥ä¸º r_feat = [å£°å­¦æè¿°ç¬¦(6) + å¯é€‰CSI(4)]ã€‚
    - ä¸“å®¶ä¸ºå°å‹MLPï¼Œè¾“å‡ºæ®‹å·® Î´yï¼Œæœ€ç»ˆ y_out = y + Î´yã€‚
    - å¼•å…¥å¯å¾®çš„è´Ÿè½½å‡è¡¡/ç†µæ­£åˆ™ä¸æ¦‚ç‡å¹³æ»‘ï¼ŒæŠ‘åˆ¶ä¸“å®¶å¡Œç¼©ï¼›å¯é€‰å¯ç”¨CSIæ„ŸçŸ¥çš„åŠ¨æ€é€‰æ‹©ã€‚
    """
    def __init__(self, d_in: int = 36, hidden: int = 64, n_experts: int = 3, top_k: int = 2, residual_scale: float = 0.2):
        super().__init__()
        self.d_in = d_in
        self.hidden = hidden
        self.n_experts = int(n_experts)
        self.top_k = int(top_k)
        self.residual_scale = float(residual_scale)
        # Schedules / warm-ups (can be overwritten by the caller)
        self.topk_warm_steps: int = 0
        self.temp_start: float = 1.5
        self.temp_end: float = 0.7
        self.temp_steps: int = 1000
        self.res_scale_start: float = residual_scale
        self.res_scale_end: float = residual_scale
        self.res_scale_steps: int = 0
        self._train_step: int = 0

        # Routerå¢å¼º/æ­£åˆ™å‚æ•°ï¼ˆå¯åœ¨å¤–éƒ¨è¦†ç›–ï¼‰
        self.router_use_csi: bool = True          # æ˜¯å¦åœ¨è·¯ç”±ä¸­ä½¿ç”¨CSIä»£ç†
        self.balance_weight: float = 0.2          # è´Ÿè½½å‡è¡¡æŸå¤±æƒé‡
        self.entropy_weight: float = 0.05         # ç†µæ­£åˆ™æƒé‡ï¼ˆæ—©æœŸæ›´å¼ºï¼‰
        self.entropy_warm_steps: int = 800        # ç†µæ­£åˆ™é€€ç«æ­¥æ•°
        self.prob_smoothing_eps: float = 0.02     # æ¦‚ç‡å¹³æ»‘ï¼Œé¿å…é›¶æ¢¯åº¦

        # Very light supervised routing: when transient is high, bias a chosen expert
        self.supervise_transient: bool = False
        self.transient_expert_id: int = 1  # default: second expert
        self.trans_thresh: float = 0.5     # on LN-normalised transient feature
        self.trans_bias: float = 0.1       # small positive bias added to logits
        self.trans_sup_steps: int = 1000   # only active in early steps

        # è·¯ç”±å™¨ï¼ˆè¾“å…¥å›ºå®šä¸º10ç»´ï¼š6å£°å­¦+4 CSIï¼›æœªå¯ç”¨CSIæ—¶ç”¨0è¡¥é½ä»¥å¯¹é½æƒé‡ï¼‰
        self.router_in_dim = 10  # [transient, continuity, harmonicness, spectral_var, energy, pitch_abs, snr, tsel, fsel, los]
        self.router_ln = nn.LayerNorm(self.router_in_dim)
        self.router_mlp = nn.Sequential(
            nn.Linear(self.router_in_dim, 16), nn.GELU(), nn.Linear(16, self.n_experts)
        )

        # ä¸“å®¶ç°‡ï¼šæ¯ä¸ªä¸“å®¶ä¸ºå°å‹MLPï¼Œæ®‹å·®è¾“å‡º
        experts = []
        for _ in range(self.n_experts):
            experts.append(nn.Sequential(
                nn.Linear(d_in, hidden), nn.GELU(), nn.Linear(hidden, d_in)
            ))
        self.experts = nn.ModuleList(experts)

        # ç ´å¯¹ç§°ä¸ç¨³å®šæ€§ï¼šä¸“å®¶é—¨æ§åç½® + è½»å¾®æŠ–åŠ¨
        self.gate_bias = nn.Parameter(torch.zeros(self.n_experts))
        nn.init.normal_(self.gate_bias, mean=0.0, std=1e-2)
        self.jitter_std: float = 1e-3

        # ç»Ÿè®¡ç¼“å­˜
        self._last_gate = None  # [B,T,E]
        self._last_top1 = None  # [B,T]

    def _router_features(self, y: torch.Tensor, csi_dict: Optional[Dict[str, torch.Tensor]] = None) -> torch.Tensor:
        """æ„é€ è·¯ç”±ç‰¹å¾ r_feat: [B,T,10] = 6(å£°å­¦) + 4(CSI)ã€‚"""
        B, T, D = y.shape
        # ç¬æ€ï¼ˆå¸§å·®ï¼‰
        dy = y[:, 1:, :] - y[:, :-1, :]
        trans = torch.zeros(B, T, device=y.device, dtype=y.dtype)
        trans[:, 1:] = dy.abs().mean(dim=-1)
        trans = trans.unsqueeze(-1)
        # è¿ç»­æ€§åå·®ï¼ˆå½“å‰ä¸æ»‘åŠ¨å‡å€¼å·®ï¼‰
        k = 5
        pad = (k - 1) // 2
        y_pad = F.pad(y.permute(0, 2, 1), (pad, pad), mode='replicate')  # [B,D,T+2p]
        y_ma = F.avg_pool1d(y_pad, kernel_size=k, stride=1, padding=0).permute(0, 2, 1)
        cont = (y - y_ma).abs().mean(dim=-1, keepdim=True)
        # è°æ³¢æ€§ï¼ˆæ¥è‡ªdnn_pitchä¸frame_corrï¼‰
        pitch = y[..., 18].clamp(-2.0, 2.0)
        pitch_abs = pitch.abs().unsqueeze(-1)
        frame_corr = y[..., 19].clamp(0.0, 1.0).unsqueeze(-1)
        harm = frame_corr  # ä½œä¸ºç®€åŒ–è°æ³¢æ€§æŒ‡æ ‡
        # é¢‘è°±ä¸ç¨³ï¼ˆLPCæ–¹å·®ï¼‰
        lpc = y[..., 20:36]
        spec_var = lpc.var(dim=-1, keepdim=True)
        # èƒ½é‡è¿‘ä¼¼ï¼ˆceps[0]ï¼‰
        energy = y[..., 0:1]
        r_acoustic = torch.cat([trans, cont, harm, spec_var, energy, pitch_abs], dim=-1)  # [B,T,6]
        # CSIä»£ç†ï¼šsnr_proxy(æˆ–ä»snr_dbæ˜ å°„)ã€time_selectivityã€freq_selectivityã€los_ratio
        if self.router_use_csi and csi_dict is not None and isinstance(csi_dict, dict) and len(csi_dict) > 0:
            def _get(key: str, default: float) -> torch.Tensor:
                t = csi_dict.get(key, None)
                if t is None:
                    return torch.full((B,), float(default), device=y.device, dtype=y.dtype)
                t = t.to(y.device).to(y.dtype)
                if t.dim() == 0:
                    t = t.view(1).expand(B)
                if t.dim() == 1 and t.size(0) == B:
                    return t
                try:
                    return t.view(B)
                except Exception:
                    return t.flatten()[:B].to(y.dtype)
            if 'snr_proxy' in csi_dict:
                snr_proxy = _get('snr_proxy', 0.0)
            else:
                snr_db = _get('snr_db', 5.0)
                snr_proxy = torch.clamp((snr_db - 7.5) / 12.5, -1.5, 1.5)
            tsel = _get('time_selectivity', 0.0)
            fsel = _get('freq_selectivity', 0.0)
            losr = _get('los_ratio', 0.0)
            def _bn(v: torch.Tensor) -> torch.Tensor:
                v = torch.clamp(v, -2.0, 2.0)
                return v.view(B, 1, 1).expand(B, T, 1)
            r_csi = torch.cat([_bn(snr_proxy), _bn(tsel), _bn(fsel), _bn(losr)], dim=-1)  # [B,T,4]
        else:
            r_csi = torch.zeros(B, T, 4, device=y.device, dtype=y.dtype)
        return torch.cat([r_acoustic, r_csi], dim=-1)  # [B,T,10]

    def forward(self, y: torch.Tensor, csi_dict: Optional[Dict[str, torch.Tensor]] = None, return_aux: bool = False):
        B, T, D = y.shape
        r = self._router_features(y, csi_dict=csi_dict)  # [B,T,10]
        r = self.router_ln(r)
        logits = self.router_mlp(r)  # [B,T,E]
        # Temperature schedule
        if self.temp_steps > 0:
            s = min(1.0, float(self._train_step) / float(self.temp_steps))
            tau = self.temp_start + (self.temp_end - self.temp_start) * s
        else:
            tau = self.temp_end
        tau = max(0.1, float(tau))
        logits = logits / tau
        logits = logits + self.gate_bias.view(1, 1, -1).to(logits.dtype)
        # Optional jitter for stability in early training
        if self.training and self.jitter_std > 0:
            logits = logits + self.jitter_std * torch.randn_like(logits)

        # Very light supervised routing (transient -> chosen expert)
        if self.supervise_transient and (self._train_step < self.trans_sup_steps):
            try:
                trans_ln = r[..., 0]  # transient after LN
                mask = (trans_ln > float(self.trans_thresh)).to(logits.dtype)
                j = max(0, min(self.transient_expert_id, self.n_experts - 1))
                bias = float(self.trans_bias)
                logits[..., j] = logits[..., j] + bias * mask
            except Exception:
                pass
        probs_soft = F.softmax(logits.float(), dim=-1).to(y.dtype)
        # æ¦‚ç‡å¹³æ»‘ï¼Œé¿å…æŸäº›ä¸“å®¶å®Œå…¨é›¶æ¢¯åº¦ï¼ˆç”¨äºæ­£åˆ™ï¼‰
        eps = float(max(0.0, min(0.1, self.prob_smoothing_eps)))
        if eps > 0.0:
            probs_soft = (1.0 - eps) * probs_soft + eps / float(self.n_experts)
        # Top-K mask + é‡æ–°å½’ä¸€åŒ–ï¼ˆç”¨äºå®é™…ä¸“å®¶èåˆï¼‰
        probs = probs_soft
        effective_k = self.top_k if (self._train_step >= self.topk_warm_steps) else 1
        effective_k = max(1, min(effective_k, self.n_experts))
        if effective_k < self.n_experts:
            topk = torch.topk(probs, k=effective_k, dim=-1)
            idx = topk.indices  # [B,T,K]
            mask = torch.zeros_like(probs)
            mask.scatter_(-1, idx, 1.0)
            probs = probs * mask
            probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)

        # ä¸“å®¶è¾“å‡ºå¹¶åŠ æƒèåˆ
        y_flat = y.reshape(B * T, D)
        outs = []
        for e in self.experts:
            outs.append(e(y_flat).reshape(B, T, D))
        outs = torch.stack(outs, dim=-1)  # [B,T,D,E]
        probs_e = probs.unsqueeze(-2)     # [B,T,1,E]
        residual = (outs * probs_e).sum(dim=-1)  # [B,T,D]
        # Residual scale ramp
        if self.res_scale_steps > 0:
            s = min(1.0, float(self._train_step) / float(self.res_scale_steps))
            scale_cur = self.res_scale_start + (self.res_scale_end - self.res_scale_start) * s
        else:
            scale_cur = self.residual_scale
        residual = float(scale_cur) * residual

        # å¯å¾®è¾…åŠ©lossï¼šå‡è¡¡ + ç†µï¼ˆæ—©æœŸå¼ºï¼Œéšæ­¥æ•°è¡°å‡ï¼‰
        util = probs_soft.mean(dim=(0, 1))  # [E]
        uni = torch.full_like(util, 1.0 / float(self.n_experts))
        lb = ((util - uni) ** 2).sum()
        ent = (- (probs_soft * (probs_soft.clamp_min(1e-8).log())).sum(dim=-1)).mean()
        if self.entropy_warm_steps > 0:
            w_ent = self.entropy_weight * (1.0 - min(1.0, float(self._train_step) / float(self.entropy_warm_steps)))
        else:
            w_ent = 0.0
        aux_loss = self.balance_weight * lb + (-w_ent) * ent

        # ç»Ÿè®¡ç¼“å­˜
        with torch.no_grad():
            self._last_gate = probs.detach().clone()  # [B,T,E]
            self._last_top1 = torch.argmax(logits, dim=-1)  # [B,T]
            self._last_res_en = residual.detach().abs().mean().item()
        if return_aux:
            return residual, {
                'balance': lb.detach(),
                'entropy': ent.detach(),
                'loss': aux_loss,
            }
        return residual

    @torch.no_grad()
    def get_stats(self) -> Dict[str, Any]:
        if self._last_gate is None:
            return {}
        g = self._last_gate  # [B,T,E]
        util = g.mean(dim=(0, 1))  # [E]
        top1 = None
        if self._last_top1 is not None:
            E = g.size(-1)
            counts = torch.bincount(self._last_top1.flatten(), minlength=E).float()
            top1 = counts / max(1, self._last_top1.numel())
        entropy = (- (g * (g.clamp_min(1e-8).log())).sum(dim=-1)).mean()  # å¹³å‡ç†µ
        return {
            'util': util.cpu().tolist(),
            'top1': top1.cpu().tolist() if top1 is not None else None,
            'entropy': float(entropy.cpu().item()),
            'residual_energy': float(getattr(self, '_last_res_en', 0.0)),
        }

    def set_training_step(self, step: int):
        self._train_step = int(step)


def test_aether_fargan_decoder():
    """æµ‹è¯•AETHER-FARGANè§£ç å™¨"""
    print("æµ‹è¯•AETHER-FARGANè§£ç å™¨æ¥å£å…¼å®¹æ€§...")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # åˆ›å»ºè§£ç å™¨
    decoder = AETHERFARGANDecoder(
        dz=24, d_csi=32, d_out=36,
        enable_synth=True,
        feature_spec_type="fargan"
    ).to(device)

    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    info = decoder.get_info()
    print(f"æ¨¡å‹ä¿¡æ¯:")
    for k, v in info.items():
        if k != 'components':
            print(f"  {k}: {v}")

    print(f"ç»„ä»¶:")
    for k, v in info['components'].items():
        print(f"  {k}: {v}")

    # æµ‹è¯•æ•°æ®
    B, T, dz = 2, 20, 24
    z = torch.randn(B, T, dz, device=device)
    csi_dict = {
        'snr_db': torch.tensor([10.0, 15.0], device=device),
        'channel_type': 'awgn'
    }

    print(f"\næµ‹è¯•æ•°æ®: z{z.shape}, CSI{list(csi_dict.keys())}")

    # æµ‹è¯•1: ä»…ç‰¹å¾é‡å»º (è¾“å‡º36ç»´FARGANç‰¹å¾)
    with torch.no_grad():
        fargan_features = decoder(z, csi_dict, return_wave=False)
        print(f"ç‰¹å¾é‡å»º: {fargan_features.shape}")
        assert fargan_features.shape == (B, T, 36), f"ç‰¹å¾ç»´åº¦é”™è¯¯: {fargan_features.shape}"

    # æµ‹è¯•2: ç‰¹å¾+æ³¢å½¢ç”Ÿæˆ (FARGANæ‰©å±•æ¥å£)
    with torch.no_grad():
        target_len = T * 160
        fargan_features, audio = decoder(z, csi_dict, return_wave=True, target_len=target_len)
        print(f"FARGANç‰¹å¾: {fargan_features.shape}")
        print(f"ç”ŸæˆéŸ³é¢‘: {audio.shape}")
        assert fargan_features.shape == (B, T, 36), f"FARGANç‰¹å¾ç»´åº¦é”™è¯¯: {fargan_features.shape}"
        assert audio.shape[-1] <= target_len, f"éŸ³é¢‘é•¿åº¦è¶…å‡ºç›®æ ‡: {audio.shape[-1]} > {target_len}"

    print(f"\nAETHER-FARGANè§£ç å™¨æµ‹è¯•é€šè¿‡!")
    print(f"   - ç»§æ‰¿AETHERDecoderæ¶æ„å’Œæ¥å£")
    print(f"   - å¤ç”¨GLABlockã€ConvRefineDecoder")
    print(f"   - ç›´æ¥è¾“å‡º36ç»´FARGANç‰¹å¾")
    print(f"   - æ‰©å±•FARGANæ³¢å½¢ç”Ÿæˆèƒ½åŠ›")


if __name__ == "__main__":
    test_aether_fargan_decoder()
