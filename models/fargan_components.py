# -*- coding: utf-8 -*-
"""
FARGAN Components for AETHER Integration
æ”¹ç¼–è‡ªåŽŸå§‹FARGANä»£ç ï¼Œé€‚é…AETHERæž¶æž„
"""

from __future__ import annotations
import math
import torch
import torch.nn as nn
import torch.nn.functional as F
# ä½¿ç”¨æ—§ç‰ˆ weight_normï¼ˆç”Ÿæˆ weight_g / weight_vï¼‰ï¼Œä»¥ä¾¿ä¸Ž Stage2 æƒé‡å®Œå…¨å¯¹é½
from torch.nn.utils import weight_norm
from typing import Tuple, Optional, Dict, Any


def add_quantization_noise(x: torch.Tensor, training: bool = True) -> torch.Tensor:
    """æ·»åŠ é‡åŒ–å™ªå£° (å¯¹åº”åŽŸå§‹FARGANçš„nå‡½æ•°)"""
    if not training:
        return x
    noise = (1.0 / 127.0) * (torch.rand_like(x) - 0.5)
    return torch.clamp(x + noise, min=-1.0, max=1.0)


class GLU(nn.Module):
    """é—¨æŽ§çº¿æ€§å•å…ƒ (Gated Linear Unit)"""

    def __init__(self, feat_size: int):
        super().__init__()
        torch.manual_seed(5)  # ä¿æŒä¸ŽåŽŸå§‹FARGANä¸€è‡´çš„éšæœºç§å­
        self.gate = weight_norm(nn.Linear(feat_size, feat_size, bias=False))
        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d, nn.Linear, nn.Embedding)):
                nn.init.orthogonal_(m.weight.data)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x * torch.sigmoid(self.gate(x))


class FWConv(nn.Module):
    """å‰å‘å·ç§¯æ¨¡å— (Frame-wise Convolution)"""

    def __init__(self, in_size: int, out_size: int, kernel_size: int = 2):
        super().__init__()
        torch.manual_seed(5)
        self.in_size = in_size
        self.kernel_size = kernel_size
        self.conv = weight_norm(nn.Linear(in_size * kernel_size, out_size, bias=False))
        self.glu = GLU(out_size)
        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d, nn.Linear, nn.Embedding)):
                nn.init.orthogonal_(m.weight.data)

    def forward(self, x: torch.Tensor, state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: [B, in_size] å½“å‰è¾“å…¥
            state: [B, in_size*(kernel_size-1)] åŽ†å²çŠ¶æ€

        Returns:
            output: [B, out_size] è¾“å‡º
            new_state: [B, in_size*(kernel_size-1)] æ›´æ–°çš„çŠ¶æ€
        """
        
        w_dtype = self.conv.weight.dtype
        if x.dtype != w_dtype:      x     = x.to(w_dtype)
        if state.dtype != w_dtype:  state = state.to(w_dtype)
        xcat = torch.cat((state, x), -1)  # [B, in_size*kernel_size]
        out = self.glu(torch.tanh(self.conv(xcat)))
        new_state = xcat[:, self.in_size:]  # æ›´æ–°çŠ¶æ€
        return out, new_state


class FARGANCond(nn.Module):
    """FARGANæ¡ä»¶ç½‘ç»œ - å°†ç‰¹å¾è½¬æ¢ä¸ºæ¡ä»¶ä¿¡å·"""

    def __init__(self, feature_dim: int = 20, cond_size: int = 256, pembed_dims: int = 12):
        super().__init__()
        self.feature_dim = feature_dim
        self.cond_size = cond_size

        # å‘¨æœŸåµŒå…¥ (Period Embedding)
        self.pembed = nn.Embedding(224, pembed_dims)  # æ”¯æŒå‘¨æœŸ32-255

        # ç‰¹å¾å¤„ç†ç½‘ç»œ
        self.fdense1 = nn.Linear(self.feature_dim + pembed_dims, 64, bias=False)
        self.fconv1 = nn.Conv1d(64, 128, kernel_size=3, padding='valid', bias=False)
        self.fdense2 = nn.Linear(128, 80 * 4, bias=False)  # 4ä¸ªå­å¸§

        self._init_weights()
        nb_params = sum(p.numel() for p in self.parameters())
        print(f"FARGANCond model: {nb_params} parameters")

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.GRU):
                for p in m.named_parameters():
                    if p[0].startswith('weight_hh_'):
                        nn.init.orthogonal_(p[1])

    def forward(self, features: torch.Tensor, period: torch.Tensor) -> torch.Tensor:
        """
        Args:
            features: [B, T, feature_dim] è¾“å…¥ç‰¹å¾
            period: [B, T] å‘¨æœŸ (32-255)

        Returns:
            cond: [B, T-2, 320] æ¡ä»¶ä¿¡å· (80*4ç»´)
        """
        # --- å…ˆåšæ—¶é—´ç»´ç¨³å¥å¯¹é½ï¼Œå†ä¸¢å‰2å¸§ ---
        # å¯¹é½åˆ°ç›¸åŒçš„æ—¶é—´é•¿åº¦ï¼Œé¿å… features/period ç›¸å·®2å¸§å¯¼è‡´ cat æŠ¥é”™
        T = min(features.size(1), period.size(1))
        if features.size(1) != T:
            features = features[:, :T, :]
        if period.size(1) != T:
            period = period[:, :T]
        # åŽ»æŽ‰å‰2å¸§ï¼Œä¿æŒä¸ŽåŽŸå§‹FARGANä¸€è‡´
        if T > 2:
            features = features[:, 2:, :]
            period = period[:, 2:]
        else:
            # ä¸è¶³ä»¥ä¸¢2å¸§æ—¶ï¼Œç›´æŽ¥è¿”å›žç©ºæ—¶é—´è½´ï¼ˆè®©ä¸Šæ¸¸é€‰æ‹©è·³è¿‡æœ¬ batch çš„ wave lossï¼‰
            return features.new_zeros(features.size(0), 0, 80 * 4)

        # å‘¨æœŸåµŒå…¥
        w_dtype = self.fdense1.weight.dtype
        period = (period - 32).clamp(0, 223).to(torch.long)     # ç´¢å¼•å¿…é¡» long
        p = self.pembed(period).to(w_dtype)                     # ä¸Žæƒé‡åŒ dtype
        features = features.to(w_dtype)                         # è¾“å…¥ä¹Ÿå¯¹é½
        features = torch.cat((features, p), -1)

        # ç½‘ç»œå‰å‘
        tmp = torch.tanh(self.fdense1(features))
        tmp = tmp.permute(0, 2, 1)  # [B, 64, T-2]
        tmp = torch.tanh(self.fconv1(tmp))  # [B, 128, T-4]
        tmp = tmp.permute(0, 2, 1)  # [B, T-4, 128]
        tmp = torch.tanh(self.fdense2(tmp))  # [B, T-4, 320]

        return tmp


class FARGANSub(nn.Module):
    """FARGANå­å¸§ç½‘ç»œ - é€å­å¸§ç”ŸæˆéŸ³é¢‘"""

    def __init__(self, subframe_size: int = 40, nb_subframes: int = 4, cond_size: int = 256):
        super().__init__()
        self.subframe_size = subframe_size
        self.nb_subframes = nb_subframes
        self.cond_size = cond_size

        # æ¡ä»¶å¢žç›Šç½‘ç»œ
        self.cond_gain_dense = nn.Linear(80, 1)

        # å‰å‘å·ç§¯å±‚
        self.fwc0 = FWConv(2 * self.subframe_size + 80 + 4, 192)

        # ä¸‰å±‚GRUç½‘ç»œ
        self.gru1 = nn.GRUCell(192 + 2 * self.subframe_size, 160, bias=False)
        self.gru2 = nn.GRUCell(160 + 2 * self.subframe_size, 128, bias=False)
        self.gru3 = nn.GRUCell(128 + 2 * self.subframe_size, 128, bias=False)

        # GLUæ¿€æ´»
        self.gru1_glu = GLU(160)
        self.gru2_glu = GLU(128)
        self.gru3_glu = GLU(128)
        self.skip_glu = GLU(128)

        # è¾“å‡ºå±‚
        self.skip_dense = nn.Linear(192 + 160 + 2 * 128 + 2 * self.subframe_size, 128, bias=False)
        self.sig_dense_out = nn.Linear(128, self.subframe_size, bias=False)
        self.gain_dense_out = nn.Linear(192, 4)  # 4ä¸ªåŸºé¢‘å¢žç›Š

        self._init_weights()
        nb_params = sum(p.numel() for p in self.parameters())
        print(f"FARGANSub model: {nb_params} parameters")

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.GRU):
                for p in m.named_parameters():
                    if p[0].startswith('weight_hh_'):
                        nn.init.orthogonal_(p[1])

    def forward(
        self,
        cond: torch.Tensor,
        prev_pred: torch.Tensor,
        exc_mem: torch.Tensor,
        period: torch.Tensor,
        states: Tuple[torch.Tensor, ...],
        gain: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, Tuple[torch.Tensor, ...]]:
        """
        Args:
            cond: [B, 80] å½“å‰å­å¸§æ¡ä»¶
            prev_pred: [B, 256] å‰ä¸€é¢„æµ‹ä¿¡å·
            exc_mem: [B, 256] æ¿€åŠ±ç¼“å†²åŒº
            period: [B] å½“å‰å‘¨æœŸ
            states: 4ä¸ªGRUçŠ¶æ€å…ƒç»„
            gain: [B, 1] å¯é€‰çš„å¤–éƒ¨å¢žç›Š

        Returns:
            sig_out: [B, subframe_size] è¾“å‡ºä¿¡å·
            exc_mem: [B, 256] æ›´æ–°çš„æ¿€åŠ±ç¼“å†²åŒº
            prev_pred: [B, 256] æ›´æ–°çš„é¢„æµ‹ä¿¡å·
            states: æ›´æ–°çš„GRUçŠ¶æ€
        """
        run_dtype = self.fwc0.conv.weight.dtype
        # å…œåº•ï¼šè‹¥ä¸Šæ¸¸å¿˜è®°æä¾› statesï¼Œè¿™é‡Œè‡ªä¸¾é›¶çŠ¶æ€
        if states is None:
            B = cond.size(0)
            states = (
                torch.zeros(B, 160, device=cond.device, dtype=run_dtype),
                torch.zeros(B, 128, device=cond.device, dtype=run_dtype),
                torch.zeros(B, 128, device=cond.device, dtype=run_dtype),
                torch.zeros(B, 2*self.subframe_size + 80 + 4, device=cond.device, dtype=run_dtype),
            )

        if cond.dtype      != run_dtype: cond      = cond.to(run_dtype)
        if prev_pred.dtype != run_dtype: prev_pred = prev_pred.to(run_dtype)
        if exc_mem.dtype   != run_dtype: exc_mem   = exc_mem.to(run_dtype)
        # states æ˜¯4ä¸ªå¼ é‡çš„tuple
        states = tuple( s.to(run_dtype) if isinstance(s, torch.Tensor) and s.dtype != run_dtype else s
                        for s in states )
        device = exc_mem.device

        # æ·»åŠ é‡åŒ–å™ªå£°
        cond = add_quantization_noise(cond, self.training)

        # æ¡ä»¶å¢žç›Š - ä¿®å¤ï¼šæ·»åŠ å¹…å€¼é™åˆ¶é˜²æ­¢éŸ³é¢‘çˆ†ç‚¸
        if gain is None:
            gain_logits = self.cond_gain_dense(cond)
            # è¿›ä¸€æ­¥é™åˆ¶å¢žç›ŠèŒƒå›´åˆ° [0.2, 1.0]ï¼Œæ›´ä¿å®ˆçš„èŒƒå›´é˜²æ­¢éŸ³é¢‘å¹…å€¼è¿‡å¤§
            gain = 0.2 + 0.8 * torch.sigmoid(gain_logits)
        if gain is not None:
            gain = torch.nan_to_num(gain, nan=1.0, posinf=20.0, neginf=1e-3).clamp_(1e-3, 20.0)
        # åŸºé¢‘é¢„æµ‹ - ä»Žæ¿€åŠ±ç¼“å†²åŒºä¸­æå–å‘¨æœŸæ€§ä¿¡å·
        idx = 256 - period[:, None]  # [B, 1]
        rng = torch.arange(self.subframe_size + 4, device=device)  # [44]
        idx = idx + rng[None, :] - 2  # [B, 44]

        # å¤„ç†å‘¨æœŸè¾¹ç•Œ
        mask = idx >= 256
        idx = idx - mask * period[:, None]

        # å¤„ç†è´Ÿç´¢å¼• - å°†è´Ÿç´¢å¼•è®¾ä¸º0
        idx = torch.clamp(idx, min=0, max=255)

        # æå–é¢„æµ‹ä¿¡å·
        pred = torch.gather(exc_mem, 1, idx)  # [B, 44]
        pred = add_quantization_noise(pred / (1e-5 + gain), self.training)

        # å‰ä¸€æ¿€åŠ±ä¿¡å·
        prev = exc_mem[:, -self.subframe_size:]  # [B, 40]
        prev = add_quantization_noise(prev / (1e-5 + gain), self.training)

        # ç»„åˆè¾“å…¥
        tmp = torch.cat((cond, pred, prev), 1)  # [B, 80+44+40]

        # æ»¤æ³¢åŽçš„åŸºé¢‘ä¿¡å·
        fpitch = pred[:, 2:-2]  # [B, 40]

        # å‰å‘å·ç§¯
        fwc0_out, fwc0_state = self.fwc0(tmp, states[3])
        fwc0_out = add_quantization_noise(fwc0_out, self.training)

        # åŸºé¢‘å¢žç›Š
        pitch_gain = torch.sigmoid(self.gain_dense_out(fwc0_out))  # [B, 4]

        # GRUå±‚çº§è”
        gru1_state = self.gru1(
            torch.cat([fwc0_out, pitch_gain[:, 0:1] * fpitch, prev], 1),
            states[0]
        )
        gru1_out = self.gru1_glu(add_quantization_noise(gru1_state, self.training))

        gru2_state = self.gru2(
            torch.cat([gru1_out, pitch_gain[:, 1:2] * fpitch, prev], 1),
            states[1]
        )
        gru2_out = self.gru2_glu(add_quantization_noise(gru2_state, self.training))

        gru3_state = self.gru3(
            torch.cat([gru2_out, pitch_gain[:, 2:3] * fpitch, prev], 1),
            states[2]
        )
        gru3_out = self.gru3_glu(add_quantization_noise(gru3_state, self.training))

        # è·³è·ƒè¿žæŽ¥
        gru_concat = torch.cat([gru1_out, gru2_out, gru3_out, fwc0_out], 1)
        skip_input = torch.cat([gru_concat, pitch_gain[:, 3:4] * fpitch, prev], 1)
        skip_out = torch.tanh(self.skip_dense(skip_input))
        skip_out = self.skip_glu(add_quantization_noise(skip_out, self.training))

        # æœ€ç»ˆè¾“å‡º
        sig_out = torch.tanh(self.sig_dense_out(skip_out))  # [B, 40]
        sig_out = sig_out * gain

        # æ›´æ–°ç¼“å†²åŒº
        exc_mem = torch.cat([exc_mem[:, self.subframe_size:], sig_out], 1)
        prev_pred = torch.cat([prev_pred[:, self.subframe_size:], fpitch], 1)

        new_states = (gru1_state, gru2_state, gru3_state, fwc0_state)

        return sig_out, exc_mem, prev_pred, new_states


class FARGANCore(nn.Module):
    """FARGANæ ¸å¿ƒæ¨¡å— - ç»„åˆæ¡ä»¶ç½‘ç»œå’Œå­å¸§ç½‘ç»œ"""

    def __init__(
        self,
        subframe_size: int = 40,
        nb_subframes: int = 4,
        feature_dim: int = 20,
        cond_size: int = 256
    ):
        super().__init__()
        self.subframe_size = subframe_size
        self.nb_subframes = nb_subframes
        self.frame_size = self.subframe_size * self.nb_subframes
        self.feature_dim = feature_dim
        self.cond_size = cond_size

        self.cond_net = FARGANCond(feature_dim=feature_dim, cond_size=cond_size)
        self.sig_net = FARGANSub(
            subframe_size=subframe_size,
            nb_subframes=nb_subframes,
            cond_size=cond_size
        )

    def forward(
        self,
        features: torch.Tensor,
        period: torch.Tensor,
        nb_frames: int,
        pre: Optional[torch.Tensor] = None,
        states: Optional[Tuple[torch.Tensor, ...]] = None
    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, ...]]:
        """
        Args:
            features: [B, T, feature_dim] è¾“å…¥ç‰¹å¾
            period: [B, T] å‘¨æœŸåºåˆ—
            nb_frames: è¦ç”Ÿæˆçš„å¸§æ•°
            pre: [B, L] å¯é€‰çš„å‰ç½®ä¿¡å·
            states: å¯é€‰çš„åˆå§‹çŠ¶æ€

        Returns:
            sig: [B, nb_frames*frame_size] ç”Ÿæˆçš„éŸ³é¢‘
            states: æœ€ç»ˆçŠ¶æ€
        """

        device = features.device
        batch_size = features.size(0)

        # === æ–°å¢žï¼šä»¥ cond_net çš„æƒé‡ä½œä¸ºå…¨ç½‘è¿è¡Œdtype ===
        model_dtype = self.cond_net.fdense1.weight.dtype
        if features.dtype != model_dtype:
            features = features.to(model_dtype)
        if pre is not None and pre.dtype != model_dtype:
            pre = pre.to(model_dtype)

        # åˆå§‹åŒ–ç¼“å†²åŒºï¼ˆæŒ‡å®š dtypeï¼‰
        prev   = torch.zeros(batch_size, 256, device=device, dtype=model_dtype)
        exc_mem= torch.zeros(batch_size, 256, device=device, dtype=model_dtype)
        # â€”â€” dtype å¯¹é½ã€deviceã€batch_size ä¿æŒä½ çŽ°æœ‰å†™æ³• â€”â€”
        # åˆå§‹åŒ– RNN/FWConv çŠ¶æ€ï¼ˆå½“ states=Noneï¼‰
        if states is None:
            states = (
                torch.zeros(batch_size, 160, device=device, dtype=model_dtype),         # GRU1
                torch.zeros(batch_size, 128, device=device, dtype=model_dtype),         # GRU2
                torch.zeros(batch_size, 128, device=device, dtype=model_dtype),         # GRU3
                torch.zeros(batch_size, 2*self.subframe_size + 80 + 4,                  # FWConv state = in_size*(k-1)
                            device=device, dtype=model_dtype),                          # 2*40 + 80 + 4 = 164
            )

        # é¢„çƒ­å¸§æ•°
        nb_pre_frames = pre.size(1) // self.frame_size if pre is not None else 0

        # ï¼ˆæŽ¨èï¼‰prime æ¿€åŠ±ç¼“å†²ä¸º pre çš„â€œæœ€åŽä¸€å¸§â€ï¼Œæ›´è´´è¿‘è‡ªå›žå½’çŠ¶æ€
        if pre is not None and pre.size(1) >= self.frame_size:
            exc_mem[:, -self.frame_size:] = pre[:, -self.frame_size:]

        # ç”Ÿæˆæ¡ä»¶ï¼ˆé•¿åº¦ = T_in - 4 = nb_framesï¼‰
        cond = self.cond_net(features, period)  # [B, nb_frames, 320]

        # â€”â€” å…³é”®ä¿®å¤ï¼šå¾ªçŽ¯ä¸¥æ ¼ä»¥ cond çš„æ—¶é—´ç»´ä¸ºå‡† â€”â€”
        # n âˆˆ [0, nb_frames-1]ï¼›è¿™æ · subframe_cond = cond[:, n, ...] æ°¸ä¸è¶Šç•Œ
        sig = torch.zeros((batch_size, 0), device=device, dtype=model_dtype)

        # å¯é€‰ï¼šå¥å£®æ€§æ–­è¨€ï¼ˆå‡ºé—®é¢˜å°±ç«‹åˆ»æ—©åœï¼Œä¾¿äºŽè¯Šæ–­ï¼‰
        assert cond.size(1) >= nb_frames, f"cond_len={cond.size(1)} < nb_frames={nb_frames}"
        assert period.size(1) >= nb_frames + 3, f"period_len={period.size(1)} < nb_frames+3={nb_frames+3}"
        if not hasattr(self, "_checked_shapes"):
            print(f"[CoreCheck] cond_len={cond.size(1)}, nb_frames={nb_frames}, "
                f"period_len={period.size(1)}, feat_len={features.size(1)}, "
                f"state_shapes={[tuple(s.shape) for s in states]}")
            self._checked_shapes = True
        for n in range(0, nb_frames):
            for k in range(self.nb_subframes):
                pos = n * self.frame_size + k * self.subframe_size

                # â€”â€” ä¸Žconvä¸­å¿ƒå¯¹é½ï¼šä½¿ç”¨ 3 + nï¼Œå¹¶åŠ ä¸Šç•Œä¿æŠ¤ï¼ˆé¿å…æœ«å°¾æžç«¯è¾¹ç•Œæ—¶ +1 è¶Šç•Œï¼‰
                per_idx  = min(3 + n, period.size(1)   - 1)
                feat_idx = min(3 + n, features.size(1) - 1)

                pitch = period[:, per_idx]
                gain = 0.03 * torch.pow(10.0, 0.5 * features[:, feat_idx, 0:1] / math.sqrt(18.0))
                gain = torch.nan_to_num(gain, nan=1.0, posinf=20.0, neginf=1e-3).clamp_(1e-3, 20.0)


                subframe_cond = cond[:, n, k * 80:(k + 1) * 80]

                out, exc_mem, prev, states = self.sig_net(
                    subframe_cond, prev, exc_mem, pitch, states, gain=gain
                )

                if (n < nb_pre_frames) and (pre is not None):
                    # teacher-forcing: ç”¨çœŸå®žæ³¢å½¢è¦†ç›–ï¼Œå¹¶æŠŠ exc_mem ä»¥çœŸå®žè¾“å‡ºæŽ¨è¿›
                    out = pre[:, pos:pos + self.subframe_size]
                    exc_mem[:, -self.subframe_size:] = out
                else:
                    # è‡ªå›žå½’ï¼šç´¯è®¡è¾“å‡º
                    sig = torch.cat([sig, out], dim=1)

        # åˆ†ç¦»çŠ¶æ€æ¢¯åº¦
        states = tuple(s.detach() for s in states)
        return sig, states



def test_fargan_components():
    """æµ‹è¯•FARGANç»„ä»¶"""
    print("ðŸ§ª æµ‹è¯•FARGANç»„ä»¶...")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    B, T = 2, 10

    # æµ‹è¯•æ¡ä»¶ç½‘ç»œ
    print("ðŸ“¡ æµ‹è¯•FARGANCond...")
    cond_net = FARGANCond(feature_dim=20).to(device)
    features = torch.randn(B, T, 20, device=device)
    period = torch.randint(32, 256, (B, T), device=device)
    cond = cond_net(features, period)
    print(f"æ¡ä»¶ç½‘ç»œ: è¾“å…¥{features.shape} -> è¾“å‡º{cond.shape}")

    # æµ‹è¯•å­å¸§ç½‘ç»œ
    print("ðŸŽµ æµ‹è¯•FARGANSub...")
    sub_net = FARGANSub().to(device)
    states = (
        torch.zeros(B, 160, device=device),
        torch.zeros(B, 128, device=device),
        torch.zeros(B, 128, device=device),
        torch.zeros(B, 124, device=device)
    )
    exc_mem = torch.randn(B, 256, device=device)
    prev_pred = torch.randn(B, 256, device=device)
    cond_sub = torch.randn(B, 80, device=device)
    period_sub = torch.randint(32, 256, (B,), device=device)

    sig_out, exc_mem_new, prev_pred_new, states_new = sub_net(
        cond_sub, prev_pred, exc_mem, period_sub, states
    )
    print(f"å­å¸§ç½‘ç»œ: è¾“å‡º{sig_out.shape}")

    # æµ‹è¯•æ ¸å¿ƒæ¨¡å—
    print("ðŸš€ æµ‹è¯•FARGANCore...")
    core = FARGANCore(feature_dim=20).to(device)
    nb_frames = 5
    pre = torch.randn(B, 160, device=device)  # 1å¸§å‰ç½®
    sig, final_states = core(features, period, nb_frames, pre=pre)
    print(f"æ ¸å¿ƒæ¨¡å—: è¾“å…¥{features.shape} -> è¾“å‡º{sig.shape}")

    print("âœ… FARGANç»„ä»¶æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    test_fargan_components()
