#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯­ä¹‰å¢å¼ºå‹AETHERè§£ç å™¨ï¼šæ’ä»¶å¼å…¼å®¹å±‚

æ ¸å¿ƒè®¾è®¡ï¼š
1. å®Œå…¨ä¿æŒAETHERDecoderçš„åŸæœ‰åŠŸèƒ½å’Œå¤æ‚åº¦
2. åœ¨36ç»´è¾“å‡ºåŸºç¡€ä¸Šå¢åŠ è¯­ä¹‰å¤„ç†æ’ä»¶
3. æ’ä»¶å¼SSLè¯­ä¹‰ç›‘ç£ï¼Œä¸ç ´ååŸæœ‰æ¶æ„
4. å‘ä¸‹å…¼å®¹ï¼Œå¯¹å¤–æ¥å£é€æ˜
"""

from __future__ import annotations
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple, Optional, Any, Union

try:
    # å°è¯•åŒ…å†…ç›¸å¯¹å¯¼å…¥
    from ..aether_encoder_decoder import AETHERDecoder
    from .semantic_latent import SemanticAdapter, LatentSpaceHead, AcousticFusionHead
except Exception:
    # å›é€€åˆ°ç»å¯¹å¯¼å…¥
    from models.aether_encoder_decoder import AETHERDecoder
    from models.semantic_latent import SemanticAdapter, LatentSpaceHead, AcousticFusionHead

try:
    from utils.feature_spec import get_default_feature_spec
except Exception:
    from dnn.torch.final_version.utils.feature_spec import get_default_feature_spec


# ä¿ç•™åŸæœ‰SemanticProcessorä»¥å…¼å®¹ç°æœ‰ä»£ç 
class SemanticProcessorLegacy(nn.Module):
    """è¯­ä¹‰å¤„ç†æ’ä»¶ï¼šå¯¹16ç»´è¯­ä¹‰ç‰¹å¾è¿›è¡Œå¢å¼ºå¤„ç†"""

    def __init__(
        self,
        semantic_dim: int = 16,
        ssl_dim: int = 768,
        enhancement_layers: int = 2,
        dropout: float = 0.1,
    ):
        super().__init__()
        self.semantic_dim = semantic_dim
        self.ssl_dim = ssl_dim

        # è¯­ä¹‰ç‰¹å¾å¢å¼ºç½‘ç»œï¼ˆä¿æŒç»´åº¦ä¸å˜ï¼‰
        if enhancement_layers == 1:
            self.enhancer = nn.Linear(semantic_dim, semantic_dim)
        else:
            mid_dim = semantic_dim * 4
            layers = []
            layers.extend([
                nn.Linear(semantic_dim, mid_dim),
                nn.GELU(),
                nn.Dropout(dropout),
            ])
            for _ in range(enhancement_layers - 2):
                layers.extend([
                    nn.Linear(mid_dim, mid_dim),
                    nn.GELU(),
                    nn.Dropout(dropout),
                ])
            layers.append(nn.Linear(mid_dim, semantic_dim))
            self.enhancer = nn.Sequential(*layers)

        # SSL teacheræŠ•å½±ï¼šå°†SSLé«˜ç»´è¡¨ç¤ºæŠ•å½±åˆ°è¯­ä¹‰ç©ºé—´
        self.ssl_to_semantic = nn.Sequential(
            nn.Linear(ssl_dim, ssl_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(ssl_dim // 2, semantic_dim)
        )

        # å¯é€‰çš„å½’ä¸€åŒ–å±‚
        self.output_norm = nn.LayerNorm(semantic_dim)
        self.ssl_norm = nn.LayerNorm(semantic_dim)

        # InfoNCEå¯¹æ¯”å­¦ä¹ ç»„ä»¶ - é˜²æ­¢ç‰¹å¾å¡Œé™·çš„æ”¹è¿›è®¾ç½®
        self.temperature = nn.Parameter(torch.tensor(0.8))  # æ›´é«˜çš„åˆå§‹æ¸©åº¦ï¼Œé˜²æ­¢è¿‡åº¦èšé›†
        self.use_infoce = True
        # æ·»åŠ è´Ÿæ ·æœ¬å¢å¼ºå‚æ•°
        self.negative_sample_ratio = 0.8  # è´Ÿæ ·æœ¬é‡‡æ ·æ¯”ä¾‹

        self._init_weights()

    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–ï¼šç¡®ä¿è®­ç»ƒåˆæœŸç¨³å®šæ€§"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                # æ›´ä¿å®ˆçš„åˆå§‹åŒ–ï¼šé˜²æ­¢è¯­ä¹‰ç‰¹å¾åˆ†å¸ƒå´©å¡Œ
                nn.init.xavier_uniform_(module.weight, gain=0.02)  # æ›´å°çš„å¢ç›Š
                if module.bias is not None:
                    nn.init.zeros_(module.bias)

        # ç‰¹åˆ«ä¿å®ˆåœ°åˆå§‹åŒ–æœ€åä¸€å±‚
        if hasattr(self.enhancer, '-1'):
            final_layer = self.enhancer[-1]
        elif isinstance(self.enhancer, nn.Linear):
            final_layer = self.enhancer
        else:
            final_layer = list(self.enhancer.modules())[-1]

        if isinstance(final_layer, nn.Linear):
            # å¢åŠ åˆå§‹åŒ–gainï¼Œé¿å…è¾“å‡ºè¿‡å°å¯¼è‡´åˆ†å¸ƒå¡Œé™·
            nn.init.xavier_uniform_(final_layer.weight, gain=0.1)  # ä»0.01å¢åŠ åˆ°0.1
            if final_layer.bias is not None:
                nn.init.zeros_(final_layer.bias)

    def forward(self, semantic_raw: torch.Tensor) -> torch.Tensor:
        """
        è¯­ä¹‰ç‰¹å¾å¢å¼ºå¤„ç†

        Args:
            semantic_raw: åŸå§‹16ç»´è¯­ä¹‰ç‰¹å¾ [B, T, 16]

        Returns:
            enhanced_semantic: å¢å¼ºåçš„16ç»´è¯­ä¹‰ç‰¹å¾ [B, T, 16]
        """
        enhanced = self.enhancer(semantic_raw)
        enhanced_semantic = self.output_norm(enhanced)
        return enhanced_semantic

    def project_ssl_teacher(self, ssl_features: torch.Tensor) -> torch.Tensor:
        """
        å°†SSL teacherç‰¹å¾æŠ•å½±åˆ°è¯­ä¹‰ç©ºé—´

        Args:
            ssl_features: SSLæ¨¡å‹è¾“å‡º [B, T, ssl_dim]

        Returns:
            ssl_semantic: æŠ•å½±åçš„è¯­ä¹‰ç‰¹å¾ [B, T, semantic_dim]
        """
        ssl_projected = self.ssl_to_semantic(ssl_features)
        ssl_semantic = self.ssl_norm(ssl_projected)
        return ssl_semantic

    def compute_semantic_loss(
        self,
        pred_semantic: torch.Tensor,
        ssl_features: torch.Tensor,
        loss_type: str = "cosine+infoce",
    ) -> Tuple[torch.Tensor, Dict[str, float]]:
        """
        è®¡ç®—è¯­ä¹‰å¯¹é½æŸå¤±

        Args:
            pred_semantic: é¢„æµ‹çš„è¯­ä¹‰ç‰¹å¾ [B, T, semantic_dim]
            ssl_features: SSL teacherç‰¹å¾ [B, T, ssl_dim]
            loss_type: æŸå¤±ç±»å‹ ("cosine", "mse", "infonce")

        Returns:
            loss: è¯­ä¹‰å¯¹é½æŸå¤±
            metrics: ç›‘æ§æŒ‡æ ‡
        """
        # æŠ•å½±SSLç‰¹å¾åˆ°è¯­ä¹‰ç©ºé—´
        ssl_semantic = self.project_ssl_teacher(ssl_features)

        if loss_type == "cosine":
            # ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±
            cos_sim = F.cosine_similarity(pred_semantic, ssl_semantic, dim=-1)
            loss = 1.0 - cos_sim.mean()

            metrics = {
                "semantic_cos_sim": cos_sim.mean().item(),
                "semantic_cos_std": cos_sim.std().item(),
            }

        elif loss_type == "mse":
            # L2è·ç¦»æŸå¤±
            loss = F.mse_loss(pred_semantic, ssl_semantic)

            with torch.no_grad():
                cos_sim = F.cosine_similarity(pred_semantic, ssl_semantic, dim=-1)
                metrics = {
                    "semantic_mse": loss.item(),
                    "semantic_cos_sim": cos_sim.mean().item(),
                }

        elif loss_type == "infonce":
            # InfoNCEå¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰
            B, T, D = pred_semantic.shape

            # L2å½’ä¸€åŒ–
            pred_norm = F.normalize(pred_semantic, p=2, dim=-1)
            ssl_norm = F.normalize(ssl_semantic, p=2, dim=-1)

            pred_flat = pred_norm.view(-1, D)
            ssl_flat = ssl_norm.view(-1, D)

            # ä½¿ç”¨å¯å­¦ä¹ æ¸©åº¦å‚æ•° - æ”¾å®½èŒƒå›´é˜²æ­¢è¿‡åº¦èšé›†
            temperature = torch.clamp(self.temperature, 0.1, 2.0)
            logits = torch.matmul(pred_flat, ssl_flat.t()) / temperature
            targets = torch.arange(B * T, device=logits.device)

            loss = F.cross_entropy(logits, targets)

            with torch.no_grad():
                cos_sim = F.cosine_similarity(pred_semantic, ssl_semantic, dim=-1)
                metrics = {
                    "semantic_infonce": loss.item(),
                    "semantic_cos_sim": cos_sim.mean().item(),
                    "semantic_temperature": temperature.item(),
                }

        elif loss_type == "cosine+infoce":
            # ç»„åˆæŸå¤±ï¼šä½™å¼¦æŸå¤± + InfoNCEæŸå¤±
            # 1. ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±
            cos_sim = F.cosine_similarity(pred_semantic, ssl_semantic, dim=-1)
            cosine_loss = 1.0 - cos_sim.mean()

            # 2. InfoNCEæŸå¤±
            B, T, D = pred_semantic.shape
            pred_norm = F.normalize(pred_semantic, p=2, dim=-1)
            ssl_norm = F.normalize(ssl_semantic, p=2, dim=-1)

            pred_flat = pred_norm.view(-1, D)
            ssl_flat = ssl_norm.view(-1, D)

            # ä½¿ç”¨å¯å­¦ä¹ æ¸©åº¦å‚æ•° - æ”¾å®½èŒƒå›´é˜²æ­¢è¿‡åº¦èšé›†
            temperature = torch.clamp(self.temperature, 0.1, 2.0)  # ä¸‹ç•Œä»0.01æå‡åˆ°0.1
            logits = torch.matmul(pred_flat, ssl_flat.t()) / temperature
            targets = torch.arange(B * T, device=logits.device)

            infonce_loss = F.cross_entropy(logits, targets)

            # ç»„åˆæŸå¤±ï¼šä½™å¼¦æŸå¤±æƒé‡0.3ï¼ŒInfoNCEæƒé‡0.7
            loss = 0.3 * cosine_loss + 0.7 * infonce_loss

            metrics = {
                "semantic_cosine": cosine_loss.item(),
                "semantic_infonce": infonce_loss.item(),
                "semantic_combined": loss.item(),
                "semantic_cos_sim": cos_sim.mean().item(),
                "semantic_temperature": temperature.item(),
            }

        else:
            raise ValueError(f"Unknown loss_type: {loss_type}")

        return loss, metrics


# ä¿ç•™åŸæœ‰SemanticFusionModuleä»¥å…¼å®¹ç°æœ‰ä»£ç 
class SemanticFusionModuleLegacy(nn.Module):
    """
    è¯­ä¹‰èåˆæ¨¡å—ï¼š16ç»´è¯­ä¹‰ç‰¹å¾æŒ‡å¯¼20ç»´å£°å­¦ç‰¹å¾ä¼˜åŒ–

    è®¾è®¡æ€è·¯ï¼š
    1. æ¥æ”¶ acoustic[20] + semantic[16]
    2. è¯­ä¹‰ç‰¹å¾ä½œä¸ºteacherï¼Œé€šè¿‡attention/gate/cross-fusionæŒ‡å¯¼å£°å­¦ç‰¹å¾
    3. è¾“å‡ºä¼˜åŒ–çš„acoustic[20] â†’ FARGAN
    """

    def __init__(
        self,
        acoustic_dim: int = 20,
        semantic_dim: int = 16,
        fusion_type: str = "attention",  # "attention", "gate", "cross_mlp"
        hidden_dim: int = 64,
        dropout: float = 0.1,
    ):
        super().__init__()
        self.acoustic_dim = acoustic_dim
        self.semantic_dim = semantic_dim
        self.fusion_type = fusion_type
        self.hidden_dim = hidden_dim

        if fusion_type == "attention":
            # è¯­ä¹‰ç‰¹å¾ä½œä¸ºqueryï¼Œå£°å­¦ç‰¹å¾ä½œä¸ºkey/value
            self.semantic_to_query = nn.Linear(semantic_dim, hidden_dim)
            self.acoustic_to_kv = nn.Linear(acoustic_dim, hidden_dim * 2)
            self.attention_fusion = nn.MultiheadAttention(hidden_dim, num_heads=4, dropout=dropout)
            self.output_proj = nn.Linear(hidden_dim, acoustic_dim)
            self.residual_logit = nn.Parameter(torch.tensor(-2.0))  # sigmoid(-2)â‰ˆ0.12ï¼Œåˆå§‹ä¿å®ˆ

        elif fusion_type == "gate":
            # è¯­ä¹‰ç‰¹å¾ç”Ÿæˆé—¨æ§ä¿¡å·è°ƒèŠ‚å£°å­¦ç‰¹å¾
            self.semantic_gate = nn.Sequential(
                nn.Linear(semantic_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(hidden_dim, acoustic_dim),
                nn.Sigmoid()  # é—¨æ§ä¿¡å· [0,1]
            )
            self.acoustic_transform = nn.Sequential(
                nn.Linear(acoustic_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(hidden_dim, acoustic_dim)
            )

        elif fusion_type == "cross_mlp":
            # äº¤å‰MLPèåˆ
            self.cross_fusion = nn.Sequential(
                nn.Linear(acoustic_dim + semantic_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(hidden_dim, hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(hidden_dim, acoustic_dim)
            )

        # è¾“å‡ºå½’ä¸€åŒ–
        self.output_norm = nn.LayerNorm(acoustic_dim)
        self._init_weights()

    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight, gain=0.1)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)

    def forward(
        self,
        acoustic_features: torch.Tensor,  # [B, T, 20]
        semantic_features: torch.Tensor,  # [B, T, 16]
    ) -> torch.Tensor:
        """
        è¯­ä¹‰æŒ‡å¯¼çš„å£°å­¦ç‰¹å¾èåˆ

        Args:
            acoustic_features: åŸå§‹å£°å­¦ç‰¹å¾ [B, T, 20]
            semantic_features: è¯­ä¹‰ç‰¹å¾ [B, T, 16]

        Returns:
            enhanced_acoustic: ä¼˜åŒ–åçš„å£°å­¦ç‰¹å¾ [B, T, 20]
        """
        B, T, _ = acoustic_features.shape

        if self.fusion_type == "attention":
            # è¯­ä¹‰â†’queryï¼Œå£°å­¦â†’key/value
            query = self.semantic_to_query(semantic_features)  # [B, T, hidden]
            kv = self.acoustic_to_kv(acoustic_features)        # [B, T, hidden*2]
            key, value = kv.chunk(2, dim=-1)                   # [B, T, hidden] each

            # Multi-head attention: semantic queries acoustic
            query = query.transpose(0, 1)  # [T, B, hidden]
            key = key.transpose(0, 1)      # [T, B, hidden]
            value = value.transpose(0, 1)  # [T, B, hidden]

            attended, _ = self.attention_fusion(query, key, value)  # [T, B, hidden]
            attended = attended.transpose(0, 1)                     # [B, T, hidden]

            enhanced_raw = self.output_proj(attended)  # [B, T, 20]
            # æ®‹å·®è¿æ¥ï¼šç‰©ç†çº¦æŸçš„æ®‹å·®æƒé‡ï¼Œæ°¸è¿œåœ¨(0,1)èŒƒå›´
            residual_scale = torch.sigmoid(self.residual_logit)  # âˆˆ(0,1)
            enhanced_acoustic = acoustic_features + residual_scale * enhanced_raw

        elif self.fusion_type == "gate":
            # è¯­ä¹‰ç”Ÿæˆé—¨æ§ä¿¡å·
            gate = self.semantic_gate(semantic_features)           # [B, T, 20]
            transformed_acoustic = self.acoustic_transform(acoustic_features)  # [B, T, 20]

            # é—¨æ§è°ƒèŠ‚ï¼šåŸå§‹ç‰¹å¾ * (1 + gate * å˜æ¢)
            enhanced_acoustic = acoustic_features * (1.0 + gate * transformed_acoustic)

        elif self.fusion_type == "cross_mlp":
            # æ‹¼æ¥èåˆ
            combined = torch.cat([acoustic_features, semantic_features], dim=-1)  # [B, T, 36]
            fusion_output = self.cross_fusion(combined)  # [B, T, 20]

            # æ®‹å·®è¿æ¥
            enhanced_acoustic = acoustic_features + fusion_output

        # æ”¹è¿›çš„å½’ä¸€åŒ–ç©ºé—´èåˆç­–ç•¥
        # 1. ä¿å­˜åŸå§‹ç»Ÿè®¡é‡ç”¨äºåå½’ä¸€åŒ–
        with torch.no_grad():
            original_mean = acoustic_features.mean(dim=[0,1], keepdim=True)
            original_std = acoustic_features.std(dim=[0,1], keepdim=True) + 1e-8

        # 2. åœ¨å½’ä¸€åŒ–ç©ºé—´ä¸­è¿›è¡Œæœ€ç»ˆèåˆ
        acoustic_normalized = (acoustic_features - original_mean) / original_std
        enhanced_normalized = (enhanced_acoustic - original_mean) / original_std

        # 3. å½’ä¸€åŒ–ç©ºé—´ä¸­çš„èŒƒå›´ä¿æŠ¤
        enhanced_std_norm = enhanced_normalized.std(dim=[0,1], keepdim=True)
        acoustic_std_norm = acoustic_normalized.std(dim=[0,1], keepdim=True)

        # é˜²æ­¢å½’ä¸€åŒ–ååˆ†å¸ƒè¿‡åº¦å‹ç¼©
        std_ratio = enhanced_std_norm / (acoustic_std_norm + 1e-8)
        std_correction = torch.where(std_ratio < 0.4, 0.4 / std_ratio, torch.ones_like(std_ratio))
        enhanced_normalized_corrected = enhanced_normalized * std_correction

        # 4. åå½’ä¸€åŒ–å›åŸå§‹ç©ºé—´
        enhanced_final = enhanced_normalized_corrected * original_std + original_mean

        # 5. æœ€åçš„LayerNormè¾“å‡ºå½’ä¸€åŒ–
        enhanced_acoustic = self.output_norm(enhanced_final)

        return enhanced_acoustic


class SemanticAugmentedAETHERDecoder(AETHERDecoder):
    """
    è¯­ä¹‰å¢å¼ºå‹AETHERè§£ç å™¨ï¼šæ’ä»¶å¼å…¼å®¹å±‚

    è®¾è®¡åŸåˆ™ï¼š
    1. å®Œå…¨ä¿æŒAETHERDecoderçš„åŸæœ‰åŠŸèƒ½ï¼ˆ36ç»´è¾“å‡ºã€åˆæˆå™¨ã€FiLMç­‰ï¼‰
    2. åœ¨36ç»´ç‰¹å¾åŸºç¡€ä¸Šè¿›è¡Œé€»è¾‘åˆ†å‰²å’Œè¯­ä¹‰å¢å¼º
    3. æ’ä»¶å¼SSLè¯­ä¹‰ç›‘ç£ï¼Œä¸ç ´ååŸæœ‰è®­ç»ƒæµç¨‹
    4. å‘ä¸‹å…¼å®¹ï¼Œå¯¹å¤–æ¥å£å®Œå…¨é€æ˜
    """

    def __init__(
        self,
        # AETHERDecoderåŸæœ‰å‚æ•°
        dz: int = 24,
        d_out: int = 36,                    # ä¿æŒ36ç»´è¾“å‡ºï¼
        d_hidden: int = 128,
        d_csi: int = 32,
        decoder_heads: int = 2,
        enable_synth: bool = True,          # ä¿æŒåˆæˆå™¨ï¼
        feature_spec_type: str = "fargan",
        use_film: bool = True,              # ä¿æŒFiLMï¼
        # è¯­ä¹‰å¢å¼ºæ’ä»¶å‚æ•°
        enable_semantic_augmentation: bool = True,
        acoustic_dim: int = 20,             # å‰20ç»´ï¼šå£°å­¦ç‰¹å¾
        semantic_dim: int = 16,             # å16ç»´ï¼šè¯­ä¹‰ç‰¹å¾
        ssl_dim: int = 768,                 # SSLæ¨¡å‹ç»´åº¦
        semantic_enhancement_layers: int = 2,
        semantic_dropout: float = 0.1,
        # æ–°æ¨¡å—å‚æ•°
        latent_dim: int = 64,               # z_semæ½œç©ºé—´ç»´åº¦
        use_cross_attention: bool = False,  # SemanticAdapteræ˜¯å¦ç”¨cross-attention
        semantic_loss_type: str = "cosine+infoce",  # LatentSpaceHeadæŸå¤±ç±»å‹
        # è¯­ä¹‰èåˆæ¨¡å—å‚æ•°
        enable_semantic_fusion: bool = True,
        fusion_type: str = "attention",     # "attention", "gate", "cross_mlp"
        fusion_hidden_dim: int = 64,
    ):
        # 1. å®Œå…¨ä¿æŒAETHERDecoderçš„åŸæœ‰åˆå§‹åŒ–
        super().__init__(
            dz=dz,
            d_out=d_out,                    # âœ“ ä¿æŒ36ç»´è¾“å‡º
            d_hidden=d_hidden,
            d_csi=d_csi,
            decoder_heads=decoder_heads,
            enable_synth=enable_synth,      # âœ“ ä¿æŒåŸæœ‰åˆæˆå™¨
            feature_spec_type=feature_spec_type,
            use_film=use_film,              # âœ“ ä¿æŒFiLMåŠŸèƒ½
        )

        # 2. è¯­ä¹‰å¢å¼ºæ’ä»¶é…ç½®
        self.enable_semantic_augmentation = enable_semantic_augmentation
        self.acoustic_dim = acoustic_dim
        self.semantic_dim = semantic_dim
        self.ssl_dim = ssl_dim

        # è¯­ä¹‰èåˆæ¨¡å—é…ç½®
        self.enable_semantic_fusion = enable_semantic_fusion
        self.fusion_type = fusion_type

        # 20ç»´â†’16ç»´è’¸é¦å¤´ï¼šå¼ºåˆ¶20ç»´ä¹Ÿèƒ½é€†å‘åˆ°è¯­ä¹‰ç©ºé—´
        self.acoustic_to_semantic_head = nn.Sequential(
            nn.Linear(acoustic_dim, acoustic_dim),
            nn.GELU(),
            nn.Dropout(semantic_dropout),
            nn.Linear(acoustic_dim, semantic_dim)
        ) if self.enable_semantic_augmentation else None

        # éªŒè¯ç»´åº¦é…ç½®
        if acoustic_dim + semantic_dim != d_out:
            raise ValueError(f"acoustic_dim({acoustic_dim}) + semantic_dim({semantic_dim}) != d_out({d_out})")

        # 3. æ–°çš„ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼ˆä»…åœ¨å¯ç”¨æ—¶åˆå§‹åŒ–ï¼‰
        if self.enable_semantic_augmentation:
            # 3.1 SemanticAdapter: semantic_raw + teacher â†’ z_sem
            self.semantic_adapter = SemanticAdapter(
                semantic_raw_dim=semantic_dim,
                teacher_dim=ssl_dim,
                latent_dim=latent_dim,
                hidden_dim=fusion_hidden_dim * 2,  # æ›´å¤§çš„hidden dim
                dropout=semantic_dropout,
                use_cross_attention=use_cross_attention,
            )

            # 3.2 LatentSpaceHead: z_sem â†’ semantic_features + loss
            self.latent_head = LatentSpaceHead(
                latent_dim=latent_dim,
                semantic_dim=semantic_dim,
                teacher_dim=ssl_dim,
                dropout=semantic_dropout,
                loss_type=semantic_loss_type,
            )

            # 3.3 AcousticFusionHead: acoustic + z_sem â†’ enhanced_acoustic
            if self.enable_semantic_fusion:
                self.acoustic_fusion_head = AcousticFusionHead(
                    acoustic_dim=acoustic_dim,
                    latent_dim=latent_dim,
                    fusion_type=fusion_type,
                    hidden_dim=fusion_hidden_dim,
                    dropout=semantic_dropout,
                )
            else:
                self.acoustic_fusion_head = None

        else:
            self.semantic_adapter = None
            self.latent_head = None
            self.acoustic_fusion_head = None

        # ä¿ç•™å…¼å®¹æ€§ï¼šæ—§æ¨¡å—ä½œä¸ºfallback
        self.semantic_processor = None
        self.semantic_fusion = None

        # 5. æš´éœ²fargan_coreå±æ€§ï¼ˆå…¼å®¹Stage2â†’4åŠ è½½ï¼‰
        # å»¶è¿Ÿåˆ°éœ€è¦æ—¶å†è°ƒç”¨ï¼Œé¿å…åˆå§‹åŒ–æ—¶çš„å¾ªç¯ä¾èµ–
        try:
            self._expose_fargan_components()
        except Exception as e:
            print(f"[WARNING] åˆå§‹åŒ–æ—¶æš´éœ²FARGANç»„ä»¶å¤±è´¥: {e}ï¼Œå°†åœ¨éœ€è¦æ—¶é‡è¯•")

    def forward(
        self,
        z: torch.Tensor,
        csi_dict_or_csi = None,             # å…¼å®¹æ—§æ¥å£
        return_wave: bool = False,
        target_len: Optional[int] = None,
        enable_semantic_output: bool = True,  # æ§åˆ¶æ˜¯å¦è¾“å‡ºè¯­ä¹‰ä¿¡æ¯
        **kwargs
    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor], Dict[str, torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­ï¼šæ’ä»¶å¼è¯­ä¹‰å¢å¼º

        Args:
            z: ç¼–ç å™¨è¾“å‡º [B, T, dz]
            csi_dict_or_csi: CSIä¿¡æ¯ï¼ˆå…¼å®¹tensorå’Œdictï¼‰
            return_wave: æ˜¯å¦è¿”å›æ³¢å½¢
            target_len: ç›®æ ‡æ³¢å½¢é•¿åº¦
            enable_semantic_output: æ˜¯å¦å¯ç”¨è¯­ä¹‰è¾“å‡º

        Returns:
            - å¦‚æœenable_semantic_output=False: ä¸åŸAETHERDecoderå®Œå…¨ä¸€è‡´çš„è¾“å‡º
            - å¦‚æœenable_semantic_output=True: åŒ…å«è¯­ä¹‰ä¿¡æ¯çš„å­—å…¸è¾“å‡º
        """
        # å…¼å®¹æ€§å¤„ç†ï¼šCSIæ ¼å¼è½¬æ¢
        if csi_dict_or_csi is None:
            csi_dict = None
        elif hasattr(csi_dict_or_csi, 'keys'):
            csi_dict = csi_dict_or_csi
        elif isinstance(csi_dict_or_csi, torch.Tensor):
            csi_dict = {'csi_tensor': csi_dict_or_csi}
        else:
            csi_dict = csi_dict_or_csi

        # 1. å®Œå…¨å¤ç”¨çˆ¶ç±»AETHERDecoderçš„å‰å‘ä¼ æ’­
        if return_wave:
            features, wave = super().forward(z, csi_dict, return_wave=True, target_len=target_len, **kwargs)
        else:
            features = super().forward(z, csi_dict, return_wave=False, **kwargs)
            wave = None

        # 2. å¦‚æœä¸éœ€è¦è¯­ä¹‰è¾“å‡ºï¼Œç›´æ¥è¿”å›åŸå§‹ç»“æœï¼ˆå®Œå…¨å…¼å®¹ï¼‰
        if not enable_semantic_output or not self.enable_semantic_augmentation:
            if return_wave:
                return features, wave
            else:
                return features

        # 3. è¯­ä¹‰å¢å¼ºå¤„ç†ï¼šåœ¨36ç»´ç‰¹å¾åŸºç¡€ä¸Šè¿›è¡Œé€»è¾‘åˆ†å‰²
        acoustic_features = features[..., :self.acoustic_dim]        # å‰20ç»´ï¼šå£°å­¦ç‰¹å¾
        semantic_raw = features[..., self.acoustic_dim:]             # å16ç»´ï¼šåŸå§‹è¯­ä¹‰ç‰¹å¾

        # 4. æ–°çš„ä¸‰é˜¶æ®µè¯­ä¹‰å¢å¼ºæµç¨‹
        if self.semantic_adapter is not None and self.latent_head is not None:
            # Step 1: semantic_raw + teacher â†’ z_semï¼ˆç»Ÿä¸€æ½œç©ºé—´ï¼‰
            teacher_features = kwargs.get('teacher_features', None)
            attn_mask = kwargs.get('attn_mask', None)

            z_sem, adapter_logs = self.semantic_adapter(
                semantic_raw,
                teacher_features=teacher_features,
                mask=attn_mask,
            )

            # Step 2: z_sem â†’ semantic_features + semantic_loss
            semantic_features, sem_loss_tensor, sem_metrics = self.latent_head(
                z_sem,
                teacher_features=teacher_features,
                mask=attn_mask,
            )

            # Step 3: acoustic + z_sem â†’ enhanced_acoustic
            if self.acoustic_fusion_head is not None:
                enhanced_acoustic_features, fusion_logs = self.acoustic_fusion_head(
                    acoustic_features,
                    z_sem,
                    mask=attn_mask,
                )
            else:
                enhanced_acoustic_features = acoustic_features
                fusion_logs = {}

        else:
            # Fallback: ä½¿ç”¨åŸå§‹ç‰¹å¾
            semantic_features = semantic_raw
            enhanced_acoustic_features = acoustic_features
            adapter_logs = {}
            sem_metrics = {}
            fusion_logs = {}
            sem_loss_tensor = semantic_raw.new_tensor(0.0)

        # 6. 20ç»´â†’16ç»´è’¸é¦ï¼šå¼ºåˆ¶20ç»´ä¿æŒè¯­ä¹‰å¯é€†æ€§
        acoustic_semantic_distill = None
        if self.acoustic_to_semantic_head is not None:
            acoustic_semantic_distill = self.acoustic_to_semantic_head(enhanced_acoustic_features)

        # 7. å¦‚æœéœ€è¦æ³¢å½¢ä¸”å¯ç”¨è¯­ä¹‰è¾“å‡ºï¼ŒåŸºäºèåˆåç‰¹å¾é‡æ–°åˆæˆ
        enhanced_wave = None
        if return_wave and enable_semantic_output:
            try:
                # æ„å»ºèåˆåçš„36ç»´ç‰¹å¾
                enhanced_features_36d = torch.cat([enhanced_acoustic_features, semantic_features], dim=-1)
                # ä½¿ç”¨èåˆåç‰¹å¾é‡æ–°åˆæˆæ³¢å½¢
                enhanced_wave = self._generate_waveform_from_enhanced_features(
                    enhanced_features_36d, target_len=target_len
                )
                # ç¡®ä¿enhanced_waveä¸ä¸ºNone
                if enhanced_wave is None:
                    print(f"[WARNING] Enhanced wave synthesis returned None, using original wave")
                    enhanced_wave = wave
            except Exception as e:
                print(f"[WARNING] Enhanced wave synthesis failed: {e}, fallback to original wave")
                enhanced_wave = wave

            # æœ€åç¡®ä¿æœ‰ä¸€ä¸ªæœ‰æ•ˆçš„æ³¢å½¢
            if enhanced_wave is None and wave is None:
                print(f"[ERROR] Both enhanced and original wave are None, generating zero wave")
                B, T = enhanced_acoustic_features.shape[:2]
                target_wav_len = target_len if target_len is not None else T * 160
                enhanced_wave = torch.zeros(B, target_wav_len, device=enhanced_acoustic_features.device, dtype=enhanced_acoustic_features.dtype)

        # 8. è¿”å›ä¸°å¯Œçš„è¾“å‡ºä¿¡æ¯
        fused36 = torch.cat([enhanced_acoustic_features, semantic_features], dim=-1)
        outputs = {
            'features': features,                # âœ“ å…¼å®¹é”®ï¼ˆåŸå§‹36ç»´ï¼Œä¿æŒä¸å˜ï¼‰
            'features_raw': features,           # âœ“ æ˜ç¡®åˆ«åï¼šæœªèåˆçš„åŸå§‹36ç»´
            'features_36d': fused36,           # âœ“ å…¼å®¹é”®ï¼ˆèåˆ36ç»´ï¼Œæ²¿ç”¨æ—§åï¼‰
            'features_fused': fused36,         # âœ“ æ˜ç¡®åˆ«åï¼šèåˆåçš„36ç»´
            'acoustic_features': enhanced_acoustic_features,    # èåˆä¼˜åŒ–åçš„20ç»´ï¼šç”¨äºFARGAN
            'acoustic_raw': acoustic_features,                  # åŸå§‹20ç»´ï¼šç”¨äºå¯¹æ¯”åˆ†æ
            'semantic_features': semantic_features,             # å¢å¼º16ç»´ï¼šç”¨äºSSLç›‘ç£
            'semantic_raw': semantic_raw,                       # åŸå§‹16ç»´ï¼šç”¨äºå¯¹æ¯”åˆ†æ
            'acoustic_semantic_distill': acoustic_semantic_distill,  # 20ç»´â†’16ç»´è’¸é¦è¾“å‡º
            'hidden_states': None,                              # å ä½ç¬¦ï¼Œä¿æŒæ¥å£ä¸€è‡´æ€§
            # æ–°å¢ï¼šä¸‰æ¨¡å—çš„ç›‘æ§ä¿¡æ¯
            'z_sem': z_sem if 'z_sem' in locals() else None,  # ç»Ÿä¸€æ½œç©ºé—´
            'adapter_logs': adapter_logs if 'adapter_logs' in locals() else {},
            'semantic_metrics': sem_metrics if 'sem_metrics' in locals() else {},
            'fusion_logs': fusion_logs if 'fusion_logs' in locals() else {},
            'semantic_loss_tensor': sem_loss_tensor if 'sem_loss_tensor' in locals() else semantic_raw.new_tensor(0.0),
        }

        # æ ¹æ®æƒ…å†µè¿”å›åŸå§‹æ³¢å½¢æˆ–èåˆæ³¢å½¢
        if return_wave:
            if enable_semantic_output and enhanced_wave is not None:
                outputs['wave'] = enhanced_wave     # ä½¿ç”¨èåˆåç‰¹å¾åˆæˆçš„æ³¢å½¢
                outputs['wave_original'] = wave     # ä¿ç•™åŸå§‹æ³¢å½¢ç”¨äºå¯¹æ¯”
            else:
                outputs['wave'] = wave

        return outputs

    def _generate_waveform_from_enhanced_features(
        self,
        enhanced_features: torch.Tensor,
        target_len: Optional[int] = None
    ) -> torch.Tensor:
        """ä½¿ç”¨èåˆåçš„36ç»´ç‰¹å¾é‡æ–°åˆæˆæ³¢å½¢ï¼ˆä¼˜å…ˆèµ°FARGANè·¯å¾„ï¼‰

        - ä¼˜å…ˆå°è¯•ç›´æ¥ä½¿ç”¨ fargan_coreï¼ˆå¦‚æœå¯ç”¨ï¼‰
        - å…¶æ¬¡å°è¯• AETHERDecoder çš„ synth/_generate_waveform
        - æœ€åå›é€€åˆ°ç‹¬ç«‹çš„ FARGANDecoder
        """
        B, T, D = enhanced_features.shape
        device = enhanced_features.device
        try:
            # ä¼˜å…ˆï¼šç›´æ¥ç”¨ fargan_coreï¼ˆè‹¥å·²æš´éœ²ï¼‰
            if hasattr(self, '_get_fargan_core'):
                fc = self._get_fargan_core()
            else:
                fc = getattr(self, 'fargan_core', None)
            if fc is not None:
                # ä¼°è®¡å‘¨æœŸ
                acoustic_part = enhanced_features[..., :20]
                try:
                    if hasattr(self, 'period_estimator') and self.period_estimator is not None:
                        period = self.period_estimator(enhanced_features)
                    else:
                        period = self._estimate_period_from_acoustic(acoustic_part)
                except Exception:
                    period = torch.full((B, T), 100, device=device, dtype=torch.long)

                # è®¡ç®—å¯ç”Ÿæˆå¸§æ•°ï¼ˆä¸FARGANCondä¸€è‡´ï¼šTâ†’T-4ï¼‰
                max_available_frames = max(1, T - 4)
                if target_len is not None:
                    target_frames_total = max(1, (int(target_len) + 160 - 1) // 160)
                    nb_frames = max(1, min(max_available_frames, target_frames_total))
                else:
                    nb_frames = max_available_frames

                # features_20 é©±åŠ¨ FARGANCore
                features_20 = acoustic_part
                audio, _ = fc(features_20, period.clamp(32, 255).to(torch.long), int(nb_frames), pre=None)
                if audio.dim() == 2:
                    audio = audio.unsqueeze(1)
                if target_len is not None and audio.size(-1) > target_len:
                    audio = audio[..., :target_len]
                return audio

            # æ¬¡ä¼˜ï¼šæœ‰ AETHERDecoder åˆæˆé“¾
            if hasattr(self, 'synth') and self.synth is not None:
                wave_result = self.synth(enhanced_features, target_len=target_len)
                if wave_result is None:
                    raise RuntimeError("Synth returned None")
                return wave_result

            if hasattr(self, '_generate_waveform'):
                acoustic_part = enhanced_features[..., :20]
                try:
                    if hasattr(self, 'period_estimator') and self.period_estimator is not None:
                        period = self.period_estimator(enhanced_features)
                    else:
                        period = self._estimate_period_from_acoustic(acoustic_part)
                except Exception:
                    period = torch.full((B, T), 100, device=device, dtype=torch.long)
                wave_result = self._generate_waveform(enhanced_features, period, target_len=target_len)
                if wave_result is None:
                    raise RuntimeError("_generate_waveform returned None")
                return wave_result

            # æœ€åï¼šç‹¬ç«‹FARGANDecoderå›é€€ï¼ˆç¡®ä¿èµ°FARGANè·¯å¾„ï¼‰
            try:
                if not hasattr(self, '_fallback_fargan_decoder') or self._fallback_fargan_decoder is None:
                    from models.fargan_decoder import FARGANDecoder as _FD
                    self._fallback_fargan_decoder = _FD()
                # ç›´æ¥ç”¨36ç»´èåˆç‰¹å¾é©±åŠ¨
                per, audio = self._fallback_fargan_decoder(enhanced_features, target_len=target_len)
                return audio
            except Exception:
                pass

            raise RuntimeError("No waveform synthesis method available")

        except Exception as e:
            print(f"[ERROR] Enhanced waveform synthesis failed: {e}")
            # ç”Ÿæˆä¸€ä¸ªå®‰å…¨çš„é›¶æ³¢å½¢è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            fallback_len = target_len if target_len is not None else T * 160
            return torch.zeros(B, fallback_len, device=device, dtype=enhanced_features.dtype)

    def _estimate_period_from_acoustic(self, acoustic_features: torch.Tensor) -> torch.Tensor:
        """ä»å£°å­¦ç‰¹å¾ä¼°è®¡periodï¼ˆç®€å•å®ç°ï¼‰

        Args:
            acoustic_features: [B, T, 20] å£°å­¦ç‰¹å¾

        Returns:
            period: [B, T] periodä¼°è®¡å€¼
        """
        B, T = acoustic_features.shape[:2]

        # ç®€å•ç­–ç•¥ï¼šä½¿ç”¨F0ç›¸å…³çš„ç»´åº¦ï¼ˆé€šå¸¸åœ¨åå‡ ç»´ï¼‰
        # å‡è®¾æŸä¸€ç»´åŒ…å«F0ä¿¡æ¯ï¼Œå°†å…¶è½¬æ¢ä¸ºperiod
        try:
            # å¦‚æœç¬¬19ç»´æ˜¯F0ç›¸å…³çš„
            f0_feature = acoustic_features[..., 18]  # ç¬¬19ç»´
            # å°†F0ç‰¹å¾æ˜ å°„åˆ°åˆç†çš„periodèŒƒå›´ (32-255)
            period = torch.clamp(
                100 + f0_feature * 50,  # åŸºç¡€period + å˜åŒ–
                32, 255
            ).round().long()
        except Exception:
            # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨å›ºå®šperiod
            period = torch.full((B, T), 100, device=acoustic_features.device, dtype=torch.long)

        return period

    def _expose_fargan_components(self):
        """æš´éœ²FARGANç»„ä»¶å±æ€§ï¼Œå…¼å®¹Stage2â†’4æƒé‡åŠ è½½"""
        try:
            print("[DEBUG] å¼€å§‹æŸ¥æ‰¾FARGANç»„ä»¶...")

            # æ–¹æ³•1ï¼šæ£€æŸ¥ç»§æ‰¿çš„AETHERDecoderæ˜¯å¦æœ‰synthå±æ€§
            if hasattr(self, 'synth') and self.synth is not None:
                print(f"[DEBUG] æ‰¾åˆ°synthå±æ€§: {type(self.synth)}")
                if hasattr(self.synth, 'fargan_core'):
                    self.fargan_core = self.synth.fargan_core
                    print("[DEBUG] é€šè¿‡synth.fargan_coreæˆåŠŸæš´éœ²")
                    return
                elif hasattr(self.synth, 'vocoder') and hasattr(self.synth.vocoder, 'fargan_core'):
                    self.fargan_core = self.synth.vocoder.fargan_core
                    print("[DEBUG] é€šè¿‡synth.vocoder.fargan_coreæˆåŠŸæš´éœ²")
                    return
                else:
                    # æ£€æŸ¥synthæ˜¯å¦æœ¬èº«å°±æ˜¯FARGANCore
                    if hasattr(self.synth, 'cond_net') or hasattr(self.synth, 'sig_net'):
                        self.fargan_core = self.synth
                        print("[DEBUG] synthæœ¬èº«å°±æ˜¯fargan_core")
                        return

            # æ–¹æ³•2ï¼šæ£€æŸ¥æ‰€æœ‰å­æ¨¡å—å¯»æ‰¾FARGANç›¸å…³ç»„ä»¶
            for name, module in self.named_modules():
                if any(keyword in name.lower() for keyword in ['fargan', 'core', 'cond', 'sig']):
                    if hasattr(module, 'cond_net') or hasattr(module, 'sig_net'):
                        self.fargan_core = module
                        print(f"[DEBUG] é€šè¿‡å­æ¨¡å— {name} æ‰¾åˆ°fargan_core")
                        return

            # æ–¹æ³•3ï¼šåˆ›å»ºä¸€ä¸ªå…¼å®¹çš„fargan_coreå±æ€§ï¼Œç”¨äºæƒé‡åŠ è½½
            print("[WARNING] æœªæ‰¾åˆ°FARGANç»„ä»¶ï¼Œåˆ›å»ºå…¼å®¹å±æ€§")
            from types import SimpleNamespace
            self.fargan_core = SimpleNamespace()
            # æ·»åŠ å¿…è¦çš„æ–¹æ³•ä½¿å…¶çœ‹èµ·æ¥åƒçœŸæ­£çš„fargan_core
            self.fargan_core.state_dict = lambda: {}
            self.fargan_core.load_state_dict = lambda state_dict, strict=True: None
            self.fargan_core.parameters = lambda: iter([])
            print("[DEBUG] åˆ›å»ºäº†å…¼å®¹çš„fargan_coreå±æ€§")

        except Exception as e:
            print(f"[WARNING] æš´éœ²FARGANç»„ä»¶å¤±è´¥: {e}")

    def _get_fargan_core(self):
        """è·å–FARGANæ ¸å¿ƒç»„ä»¶ï¼Œæ”¯æŒå¤šç§è·¯å¾„"""
        if hasattr(self, 'fargan_core') and self.fargan_core is not None:
            return self.fargan_core

        # å¦‚æœæ²¡æœ‰fargan_coreï¼Œå°è¯•é‡æ–°æš´éœ²
        self._expose_fargan_components()

        if hasattr(self, 'fargan_core'):
            return self.fargan_core
        else:
            print("[ERROR] æ— æ³•è·å–fargan_coreç»„ä»¶")
            return None

    def compute_semantic_loss(
        self,
        semantic_features: torch.Tensor,
        ssl_features: torch.Tensor,
        loss_type: str = "cosine",
        # Waveçº§è¯­ä¹‰çº¦æŸå‚æ•°
        wave_gt: Optional[torch.Tensor] = None,
        wave_rec: Optional[torch.Tensor] = None,
        ssl_extractor = None,
        wave_semantic_weight: float = 0.3,
        # 20ç»´â†’16ç»´è’¸é¦å‚æ•°
        acoustic_semantic_distill: Optional[torch.Tensor] = None,
        distill_weight: float = 0.5,
        # ğŸ”¥ æ–°å¢ï¼šæ½œç©ºé—´ç‰¹å¾å‚æ•°
        z_sem: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, Dict[str, float]]:
        """è®¡ç®—è¯­ä¹‰å¯¹é½æŸå¤±ï¼ˆä½¿ç”¨æ–°çš„LatentSpaceHeadï¼‰"""
        if not self.enable_semantic_augmentation or self.latent_head is None:
            # å¦‚æœæœªå¯ç”¨è¯­ä¹‰å¢å¼ºï¼Œè¿”å›é›¶æŸå¤±
            device = semantic_features.device
            zero_loss = torch.tensor(0.0, device=device, requires_grad=True)
            return zero_loss, {"semantic_disabled": 1.0}

        # ğŸ”¥ ä½¿ç”¨æ½œç©ºé—´ç‰¹å¾z_semè®¡ç®—è¯­ä¹‰æŸå¤±

        # å¤„ç†semantic_featuresç»´åº¦
        B, T = semantic_features.shape[:2]
        if semantic_features.dim() == 4:
            semantic_features_2d = semantic_features.squeeze(-1)  # [B, T, 16]
        else:
            semantic_features_2d = semantic_features

        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„z_semï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•é‡æ–°ç”Ÿæˆ
        if z_sem is not None:
            # ä½¿ç”¨ä¼ å…¥çš„æ½œç©ºé—´ç‰¹å¾ç›´æ¥è®¡ç®—æŸå¤±
            try:
                # ğŸ”§ ä¿®å¤æ—¶é—´ç»´åº¦å¯¹é½é—®é¢˜
                T_ssl = ssl_features.shape[1]  # SSLç‰¹å¾çš„æ—¶é—´ç»´åº¦
                T_z = z_sem.shape[1]          # z_semçš„æ—¶é—´ç»´åº¦

                # å¯¹é½æ—¶é—´ç»´åº¦ï¼šä¸‹é‡‡æ ·éŸ³é¢‘ç‰¹å¾åˆ°SSLå¸§ç‡ (è¯­ä¹‰çº§åˆ«)
                if T_z != T_ssl:

                    if abs(T_z - T_ssl * 2) < abs(T_z - T_ssl):
                        # æ£€æµ‹åˆ°2å€å…³ç³»ï¼Œä¸‹é‡‡æ ·z_semåˆ°SSLçš„è¯­ä¹‰å¸§ç‡
                        z_sem_aligned = F.interpolate(
                            z_sem.transpose(1, 2),  # [B, latent_dim, T_z]
                            size=T_ssl,
                            mode='linear',
                            align_corners=False
                        ).transpose(1, 2)  # [B, T_ssl, latent_dim]
                        ssl_features_aligned = ssl_features
                    elif T_z > T_ssl:
                        # ç®€å•æˆªæ–­ï¼šå–å‰T_sslä¸ªæ—¶é—´æ­¥
                        z_sem_aligned = z_sem[:, :T_ssl, :]
                        ssl_features_aligned = ssl_features
                    else:
                        # SSLæ›´é•¿ï¼Œæˆªæ–­SSL
                        z_sem_aligned = z_sem
                        ssl_features_aligned = ssl_features[:, :T_z, :]
                else:
                    z_sem_aligned = z_sem
                    ssl_features_aligned = ssl_features


                # é€šè¿‡LatentSpaceHeadè®¡ç®—æŸå¤±
                _, sem_loss_tensor, sem_metrics = self.latent_head(
                    z_sem_aligned,  # [B, T_aligned, latent_dim]
                    teacher_features=ssl_features_aligned,  # [B, T_aligned, ssl_dim]
                    mask=None,
                )

                base_loss = sem_loss_tensor
                base_metrics = sem_metrics.copy()
                # ğŸ”¥ å•ç‹¬è®°å½•æ½œç©ºé—´è¯­ä¹‰æŸå¤±ï¼Œç”¨äºä¸æ€»è¯­ä¹‰æŸå¤±å¯¹æ¯”
                base_metrics['latent_sem_loss'] = sem_loss_tensor.item()
                print(f"âœ… æ½œç©ºé—´è¯­ä¹‰æŸå¤±: {base_loss.item():.6f}")

            except Exception as e:
                print(f"âš ï¸ ä½¿ç”¨ä¼ å…¥z_semè®¡ç®—æŸå¤±å¤±è´¥: {e}")
                # å›é€€åˆ°ç®€å•æŸå¤±ï¼Œç¡®ä¿ç»´åº¦å¯¹é½
                T_min = min(semantic_features_2d.shape[1], ssl_features.shape[1])
                semantic_aligned = semantic_features_2d[:, :T_min, :]
                ssl_aligned = ssl_features[:, :T_min, :semantic_aligned.shape[-1]]
                base_loss = F.mse_loss(semantic_aligned, ssl_aligned)
                base_metrics = {"fallback_mse": base_loss.item()}

        elif hasattr(self, 'semantic_adapter') and self.semantic_adapter is not None:
            # å¦‚æœæ²¡æœ‰ä¼ å…¥z_semï¼Œå°è¯•é‡æ–°ç”Ÿæˆ
            try:
                print("ğŸ”„ é‡æ–°ç”Ÿæˆæ½œç©ºé—´ç‰¹å¾ z_sem")

                # ç¡®ä¿æ—¶é—´ç»´åº¦å¯¹é½
                T_min = min(semantic_features_2d.shape[1], ssl_features.shape[1])
                semantic_aligned = semantic_features_2d[:, :T_min, :]
                ssl_aligned = ssl_features[:, :T_min, :]

                z_sem_generated, adapter_logs = self.semantic_adapter(
                    semantic_aligned,  # [B, T_min, 16] ä½œä¸ºsemantic_raw
                    teacher_features=ssl_aligned,  # SSL features
                    mask=None,
                )

                # é€šè¿‡LatentSpaceHeadè®¡ç®—æŸå¤±
                _, sem_loss_tensor, sem_metrics = self.latent_head(
                    z_sem_generated,  # [B, T_min, latent_dim]
                    teacher_features=ssl_aligned,
                    mask=None,
                )

                base_loss = sem_loss_tensor
                base_metrics = sem_metrics.copy()
                # ğŸ”¥ å•ç‹¬è®°å½•æ½œç©ºé—´è¯­ä¹‰æŸå¤±ï¼Œç”¨äºä¸æ€»è¯­ä¹‰æŸå¤±å¯¹æ¯”
                base_metrics['latent_sem_loss'] = sem_loss_tensor.item()
                print(f"âœ… é‡æ–°ç”Ÿæˆçš„æ½œç©ºé—´è¯­ä¹‰æŸå¤±: {base_loss.item():.6f}")

            except Exception as e:
                print(f"âš ï¸ é‡æ–°ç”Ÿæˆz_semè®¡ç®—æŸå¤±å¤±è´¥: {e}")
                # å›é€€åˆ°ç®€å•æŸå¤±
                T_min = min(semantic_features_2d.shape[1], ssl_features.shape[1])
                semantic_aligned = semantic_features_2d[:, :T_min, :]
                ssl_aligned = ssl_features[:, :T_min, :semantic_aligned.shape[-1]]
                base_loss = F.mse_loss(semantic_aligned, ssl_aligned)
                base_metrics = {"fallback_mse": base_loss.item()}
        else:
            print("âš ï¸ semantic_adapteræœªåˆå§‹åŒ–ä¸”æœªä¼ å…¥z_semï¼Œä½¿ç”¨ç®€å•å¯¹é½æŸå¤±")
            # å›é€€åˆ°ç®€å•çš„ç‰¹å¾å¯¹é½ï¼Œç¡®ä¿ç»´åº¦å¯¹é½
            T_min = min(semantic_features_2d.shape[1], ssl_features.shape[1])
            semantic_aligned = semantic_features_2d[:, :T_min, :]
            ssl_aligned = ssl_features[:, :T_min, :semantic_aligned.shape[-1]]
            base_loss = F.mse_loss(semantic_aligned, ssl_aligned)
            base_metrics = {"simple_mse": base_loss.item()}

        total_loss = base_loss
        total_metrics = base_metrics.copy()

        # Waveçº§è¯­ä¹‰çº¦æŸï¼šæœ€ç›´æ¥çš„è¯­ä¹‰ä¿æŒ
        if wave_gt is not None and wave_rec is not None and ssl_extractor is not None:
            try:
                # æå–åŸå§‹å’Œé‡å»ºæ³¢å½¢çš„SSLè¯­ä¹‰ç‰¹å¾
                with torch.no_grad():
                    ssl_semantic_gt = ssl_extractor(wave_gt)  # [B, T, ssl_dim]
                    ssl_semantic_rec = ssl_extractor(wave_rec)  # [B, T, ssl_dim]

                # æ—¶é—´å¯¹é½åˆ°ç‰¹å¾å¸§ç‡
                if ssl_semantic_gt.size(1) != semantic_features.size(1):
                    ssl_semantic_gt = F.interpolate(
                        ssl_semantic_gt.transpose(1, 2),
                        size=semantic_features.size(1),
                        mode='linear', align_corners=False
                    ).transpose(1, 2)

                if ssl_semantic_rec.size(1) != semantic_features.size(1):
                    ssl_semantic_rec = F.interpolate(
                        ssl_semantic_rec.transpose(1, 2),
                        size=semantic_features.size(1),
                        mode='linear', align_corners=False
                    ).transpose(1, 2)

                # Waveçº§è¯­ä¹‰æŸå¤±ï¼šé‡å»ºæ³¢å½¢çš„è¯­ä¹‰åº”è¯¥æ¥è¿‘åŸå§‹æ³¢å½¢
                wave_semantic_loss = F.cosine_embedding_loss(
                    ssl_semantic_rec.view(-1, ssl_semantic_rec.size(-1)),
                    ssl_semantic_gt.view(-1, ssl_semantic_gt.size(-1)),
                    torch.ones(ssl_semantic_rec.size(0) * ssl_semantic_rec.size(1),
                              device=ssl_semantic_rec.device)
                )

                total_loss = total_loss + wave_semantic_weight * wave_semantic_loss
                total_metrics['wave_semantic_loss'] = wave_semantic_loss.item()
                total_metrics['wave_semantic_weight'] = wave_semantic_weight

            except Exception as e:
                # Waveçº§çº¦æŸå¤±è´¥æ—¶å›é€€åˆ°åŸºç¡€æŸå¤±
                total_metrics['wave_semantic_error'] = str(e)

        # 20ç»´â†’16ç»´è’¸é¦æŸå¤±ï¼šå¼ºåˆ¶20ç»´ä¿æŒè¯­ä¹‰å¯é€†æ€§
        if acoustic_semantic_distill is not None:
            # å°†20ç»´æŠ•å½±çš„è¾“å‡ºä¸16ç»´è¯­ä¹‰ç‰¹å¾å¯¹é½
            distill_loss = F.cosine_embedding_loss(
                acoustic_semantic_distill.view(-1, acoustic_semantic_distill.size(-1)),
                semantic_features.view(-1, semantic_features.size(-1)),
                torch.ones(acoustic_semantic_distill.size(0) * acoustic_semantic_distill.size(1),
                          device=acoustic_semantic_distill.device)
            )

            total_loss = total_loss + distill_weight * distill_loss
            total_metrics['acoustic_semantic_distill_loss'] = distill_loss.item()
            total_metrics['distill_weight'] = distill_weight

        total_metrics['total_semantic_loss'] = total_loss.item()
        return total_loss, total_metrics

    def get_semantic_info(self) -> Dict[str, Any]:
        """è·å–è¯­ä¹‰å¢å¼ºé…ç½®ä¿¡æ¯"""
        return {
            'enable_semantic_augmentation': self.enable_semantic_augmentation,
            'acoustic_dim': self.acoustic_dim,
            'semantic_dim': self.semantic_dim,
            'ssl_dim': self.ssl_dim,
            'total_feature_dim': self.acoustic_dim + self.semantic_dim,
            'has_semantic_processor': self.semantic_processor is not None,
            # è¯­ä¹‰èåˆæ¨¡å—ä¿¡æ¯
            'enable_semantic_fusion': self.enable_semantic_fusion,
            'has_semantic_fusion': self.semantic_fusion is not None,
            'fusion_type': getattr(self, 'fusion_type', 'none'),
            'fusion_flow': '36D â†’ 20D+16D â†’ SemanticFusion â†’ Enhanced20D â†’ FARGAN',
            'original_aether_preserved': True,  # å¼ºè°ƒä¿æŒäº†åŸæœ‰åŠŸèƒ½
            # æ·»åŠ æ®‹å·®æƒé‡ä¿¡æ¯
            'residual_logit': getattr(self.semantic_fusion, 'residual_logit', None),
            'current_residual_scale': torch.sigmoid(self.semantic_fusion.residual_logit).item() if hasattr(self.semantic_fusion, 'residual_logit') else None
        }

    def enable_semantic_mode(self):
        """å¯ç”¨è¯­ä¹‰å¢å¼ºæ¨¡å¼"""
        self.enable_semantic_augmentation = True
        if self.semantic_processor is not None:
            self.semantic_processor.train(True)

    def disable_semantic_mode(self):
        """ç¦ç”¨è¯­ä¹‰å¢å¼ºæ¨¡å¼ï¼ˆå›é€€åˆ°çº¯AETHERDecoderï¼‰"""
        self.enable_semantic_augmentation = False
        if self.semantic_processor is not None:
            self.semantic_processor.train(False)


def create_semantic_augmented_decoder(
    config: Dict[str, Any],
    enable_semantic: bool = True,
    ssl_model_type: str = "hubert-base",
    # è¯­ä¹‰èåˆå‚æ•°
    enable_fusion: bool = True,
    fusion_type: str = "attention",
    fusion_hidden_dim: int = 64,
    semantic_enhancement_layers: int = 2,
    semantic_dropout: float = 0.1,
) -> SemanticAugmentedAETHERDecoder:
    """
    åˆ›å»ºè¯­ä¹‰å¢å¼ºè§£ç å™¨çš„ä¾¿æ·å‡½æ•°

    Args:
        config: é…ç½®å­—å…¸
        enable_semantic: æ˜¯å¦å¯ç”¨è¯­ä¹‰å¢å¼º
        ssl_model_type: SSLæ¨¡å‹ç±»å‹

    Returns:
        SemanticAugmentedAETHERDecoderå®ä¾‹
    """
    # SSLç»´åº¦æ˜ å°„
    ssl_dim_map = {
        "hubert-base": 768,
        "hubert-large": 1024,
        "wavlm-base": 768,
        "wavlm-large": 1024,
    }

    ssl_dim = ssl_dim_map.get(ssl_model_type, 768)

    return SemanticAugmentedAETHERDecoder(
        dz=config.get("dz", 24),
        d_out=config.get("d_out", 36),              # ä¿æŒ36ç»´
        d_hidden=config.get("d_hidden", 128),
        d_csi=config.get("d_csi", 32),
        decoder_heads=config.get("decoder_heads", 2),
        enable_synth=config.get("enable_synth", True),  # ä¿æŒåˆæˆå™¨
        feature_spec_type=config.get("feature_spec_type", "fargan"),
        use_film=config.get("use_film", True),          # ä¿æŒFiLM
        # è¯­ä¹‰å¢å¼ºå‚æ•°
        enable_semantic_augmentation=enable_semantic,
        acoustic_dim=20,
        semantic_dim=16,
        ssl_dim=ssl_dim,
        semantic_enhancement_layers=semantic_enhancement_layers,
        semantic_dropout=semantic_dropout,
        # è¯­ä¹‰èåˆå‚æ•°
        enable_semantic_fusion=enable_fusion,
        fusion_type=fusion_type,
        fusion_hidden_dim=fusion_hidden_dim,
    )


# å‘ä¸‹å…¼å®¹åˆ«å
DualHeadAETHERFARGANDecoder = SemanticAugmentedAETHERDecoder
create_dual_head_decoder = create_semantic_augmented_decoder


if __name__ == "__main__":
    # æµ‹è¯•è¯­ä¹‰å¢å¼ºAETHERè§£ç å™¨
    print("Testing SemanticAugmentedAETHERDecoder...")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len = 2, 50
    dz, d_csi = 24, 32

    z = torch.randn(batch_size, seq_len, dz)
    csi = torch.randn(batch_size, seq_len, d_csi)
    ssl_features = torch.randn(batch_size, seq_len, 768)

    # åˆ›å»ºè¯­ä¹‰å¢å¼ºè§£ç å™¨
    config = {
        "dz": dz,
        "d_out": 36,
        "d_hidden": 128,
        "d_csi": d_csi,
        "decoder_heads": 2,
    }

    decoder = create_semantic_augmented_decoder(config, enable_semantic=True)

    print(f"Input z shape: {z.shape}")
    print(f"Input csi shape: {csi.shape}")

    # æµ‹è¯•1ï¼šå…¼å®¹æ¨¡å¼ï¼ˆä¸åŸAETHERDecoderå®Œå…¨ä¸€è‡´ï¼‰
    print("\n=== å…¼å®¹æ¨¡å¼æµ‹è¯• ===")
    features_compat = decoder(z, csi, enable_semantic_output=False)
    print(f"Compatible output shape: {features_compat.shape}")

    # æµ‹è¯•2ï¼šè¯­ä¹‰å¢å¼ºæ¨¡å¼
    print("\n=== è¯­ä¹‰å¢å¼ºæ¨¡å¼æµ‹è¯• ===")
    outputs = decoder(z, csi, enable_semantic_output=True, return_wave=True)

    print("Semantic augmented outputs:")
    for key, value in outputs.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape}")
        else:
            print(f"  {key}: {value}")

    # æµ‹è¯•3ï¼šè¯­ä¹‰æŸå¤±è®¡ç®—
    print("\n=== è¯­ä¹‰æŸå¤±æµ‹è¯• ===")
    semantic_loss, metrics = decoder.compute_semantic_loss(
        outputs['semantic_features'],
        ssl_features,
        loss_type="cosine"
    )

    print(f"Semantic loss: {semantic_loss.item():.6f}")
    print(f"Metrics: {metrics}")

    # æµ‹è¯•4ï¼šé…ç½®ä¿¡æ¯
    print("\n=== é…ç½®ä¿¡æ¯ ===")
    info = decoder.get_semantic_info()
    for k, v in info.items():
        print(f"  {k}: {v}")

    print("\nâœ… SemanticAugmentedAETHERDecoder test completed!")
