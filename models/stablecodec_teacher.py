"""
StableCodec Teacher wrapper for hash-bottleneck distillation.

è®¾è®¡ç›®æ ‡ï¼ˆå¯¹ç…§ stage5_docs/3.mdï¼‰ï¼š
1. å½“ä¾èµ–æ»¡è¶³æ—¶ï¼Œç›´æ¥è°ƒç”¨ external_repos/stable-codec æä¾›çš„ StableCodec æ¨¡å‹åšæ¨ç†ï¼Œ
   åªç”¨äº encodeï¼ˆæå– pre-bottleneck latentï¼‰ï¼Œä¸å‚ä¸è®­ç»ƒã€‚
2. å½“ä¾èµ–/ç¯å¢ƒä¸åŒ¹é…ï¼ˆç¼ºå°‘ stable-audio-toolsã€é¢„è®­ç»ƒæƒé‡ç­‰ï¼‰æ—¶ï¼Œä¼˜é›…é™çº§ä¸ºè½»é‡ mockï¼Œ
   æˆ–ä½¿ç”¨ç¦»çº¿é¢„è®¡ç®— latentï¼ˆPrecomputedStableCodecTeacherï¼‰ã€‚
3. æä¾›ç»Ÿä¸€æ¥å£ï¼šencode_latent(audio, align_to_fargan=True) â†’ [B, T_frames, D_teacher]ã€‚
"""

from __future__ import annotations

import os
import sys
import warnings
from pathlib import Path
from typing import Optional, Dict, Any, Tuple, Union

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchaudio  # ç”¨äºå¯é€‰çš„é‡é‡‡æ ·


def _import_stablecodec_class() -> Optional[type]:
    """
    å°è¯•ä» external_repos/stable-codec ä¸­å¯¼å…¥ StableCodec ç±»ã€‚
    å¦‚æœ stable-audio-tools æˆ–å…¶å®ƒä¾èµ–ç¼ºå¤±ï¼Œåˆ™è¿”å› Noneã€‚
    """
    try:
        # å…ˆå°è¯•ç›´æ¥å¯¼å…¥ï¼ˆç”¨æˆ·å¯èƒ½å·²ç» pip å®‰è£…è¿‡ stable-codecï¼‰
        from stable_codec.model import StableCodec  # type: ignore
        return StableCodec
    except Exception:
        pass

    # å†å°è¯•ä»æœ¬ä»“åº“ external_repos ä¸­å¯¼å…¥
    try:
        repo_root = Path(__file__).resolve().parents[2] / "external_repos" / "stable-codec"
        if repo_root.is_dir():
            if str(repo_root) not in sys.path:
                sys.path.insert(0, str(repo_root))
            from stable_codec.model import StableCodec  # type: ignore
            return StableCodec
    except Exception:
        return None

    return None


class StableCodecTeacher(nn.Module):
    """
    StableCodec Teacher å°è£…ï¼š

    - ä¼˜å…ˆä½¿ç”¨ external_repos/stable-codec çš„ StableCodec è¿›è¡Œæ¨ç†ï¼›
    - å¦‚æœä¾èµ–ä¸æ»¡è¶³æˆ–å®ä¾‹åŒ–å¤±è´¥ï¼Œåˆ™è‡ªåŠ¨é™çº§ä¸ºè½»é‡ Mock encoderï¼›
    - encode_latent() å§‹ç»ˆè¿”å› [B, T_frames, D] çš„è¿ç»­ latentã€‚
    """

    def __init__(
        self,
        pretrained_model: Optional[str] = "stabilityai/stable-codec-speech-16k",
        model_config_path: Optional[str] = None,
        ckpt_path: Optional[str] = None,
        device: Optional[Union[str, torch.device]] = None,
        use_mock_if_unavailable: bool = True,
        fargan_frame_rate: float = 100.0,
    ):
        super().__init__()

        if device is None:
            device = "cuda" if torch.cuda.is_available() else "cpu"
        self.device = torch.device(device)

        self.fargan_frame_rate = float(fargan_frame_rate)
        self.backend = "mock"  # "stablecodec" æˆ– "mock"
        self.sample_rate = 16000  # é»˜è®¤å€¼ï¼Œåé¢æ ¹æ® StableCodec è¦†ç›–
        self.teacher_dim: Optional[int] = None

        StableCodecCls = _import_stablecodec_class()
        self._sc = None

        if StableCodecCls is not None and (pretrained_model or model_config_path):
            try:
                # å°è¯•æ„é€  StableCodec å®ä¾‹ï¼ˆåªåšæ¨ç†ï¼‰
                kwargs_sc: Dict[str, Any] = {"device": self.device}
                if pretrained_model is not None:
                    kwargs_sc["pretrained_model"] = pretrained_model
                else:
                    kwargs_sc["model_config_path"] = model_config_path
                    if ckpt_path is not None:
                        kwargs_sc["ckpt_path"] = ckpt_path

                self._sc = StableCodecCls(**kwargs_sc)  # type: ignore
                self._sc.eval().requires_grad_(False)
                # sample_rate / teacher_dim ä»æ¨¡å‹é…ç½®ä¸­è¯»å–
                try:
                    self.sample_rate = int(getattr(self._sc, "sample_rate", self.sample_rate))
                except Exception:
                    pass

                self.backend = "stablecodec"
                warnings.warn(
                    f"StableCodecTeacher: using StableCodec backend "
                    f"(pretrained_model={pretrained_model}, sample_rate={self.sample_rate})."
                )
            except Exception as e:
                # ä¾èµ–ä¸æ»¡è¶³æˆ–åŠ è½½å¤±è´¥ï¼Œé™çº§åˆ° mock
                if not use_mock_if_unavailable:
                    raise RuntimeError(f"Failed to initialise StableCodecTeacher backend: {e}") from e
                warnings.warn(
                    f"StableCodecTeacher: failed to init StableCodec backend ({e}); "
                    f"falling back to mock encoder."
                )
                self.backend = "mock"
        else:
            if not use_mock_if_unavailable:
                raise RuntimeError(
                    "StableCodecTeacher: StableCodec backend unavailable "
                    "(missing stable-codec / stable-audio-tools); "
                    "set use_mock_if_unavailable=True or use PrecomputedStableCodecTeacher."
                )
            warnings.warn(
                "StableCodecTeacher: stable-codec dependencies not available; using mock encoder."
            )
            self.backend = "mock"

        # Mock encoderï¼ˆä»…åœ¨ backend == 'mock' æ—¶ä½¿ç”¨ï¼‰
        if self.backend == "mock":
            # çº¦ 25Hzï¼šstride 640 at 16kHz â†’ 25 frames/s
            self.mock_encoder = nn.Sequential(
                nn.Conv1d(1, 32, kernel_size=1024, stride=640, padding=192),
                nn.BatchNorm1d(32),
                nn.GELU(),
                nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),
                nn.BatchNorm1d(64),
                nn.GELU(),
                nn.Conv1d(64, 6, kernel_size=1, stride=1, padding=0),
            )
            self.teacher_dim = 6

    def _preprocess_audio_tensor(self, audio: torch.Tensor) -> torch.Tensor:
        """
        é¢„å¤„ç†éŸ³é¢‘ tensor åˆ° StableCodec æœŸæœ›çš„å½¢çŠ¶ [B, 1, T]ã€‚
        ä¸åšé‡é‡‡æ ·ï¼Œå‡å®šå¤–éƒ¨å·²æä¾›ä¸ StableCodec ä¸€è‡´çš„é‡‡æ ·ç‡ï¼ˆé€šå¸¸ 16kHzï¼‰ã€‚
        """
        if audio.dim() == 1:
            audio = audio.unsqueeze(0)  # [1, T]
        if audio.dim() == 2:
            # [B, T] -> [B, 1, T]
            audio = audio.unsqueeze(1)
        if audio.dim() == 3 and audio.size(1) != 1:
            # å¤šé€šé“è½¬å•é€šé“
            audio = audio.mean(dim=1, keepdim=True)
        return audio.to(self.device)

    @torch.no_grad()
    def encode_latent(
        self,
        audio: Union[torch.Tensor, str],
        align_to_fargan: bool = True,
        posthoc_bottleneck: bool = False,
    ) -> torch.Tensor:
        """
        æå– StableCodec pre-bottleneck latentã€‚

        Args:
            audio: [B, T] / [B, 1, T] æˆ– wav è·¯å¾„ï¼ˆstrï¼‰
            align_to_fargan: æ˜¯å¦ä¸Šé‡‡æ ·åˆ° FARGAN å¸§ç‡ï¼ˆé»˜è®¤ 100Hzï¼‰
            posthoc_bottleneck: æ˜¯å¦ä½¿ç”¨ posthoc bottleneckï¼ˆä¸ stable-codec ä¸€è‡´ï¼‰

        Returns:
            latent: [B, T_frames, D]ï¼Œè‹¥ align_to_fargan=Trueï¼Œåˆ™ T_framesâ‰ˆT_audio/160
        """
        # 1) è¯»å–/é¢„å¤„ç†éŸ³é¢‘
        if isinstance(audio, str):
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨ torchaudio è¯»å–å¹¶è½¬æ¢ä¸º StableCodec é‡‡æ ·ç‡
            wav, sr = torchaudio.load(audio)
            if sr != self.sample_rate:
                try:
                    wav = torchaudio.functional.resample(wav, sr, self.sample_rate)
                except Exception:
                    # é€€åŒ–ä¸ºæœ€è¿‘é‚» up/down-sample
                    target_len = int(wav.shape[-1] * self.sample_rate / sr)
                    wav = F.interpolate(
                        wav.unsqueeze(1),
                        size=target_len,
                        mode="linear",
                        align_corners=False,
                    ).squeeze(1)
            audio_tensor = wav.to(self.device)
        else:
            audio_tensor = audio

        audio_tensor = self._preprocess_audio_tensor(audio_tensor)  # [B,1,T]
        B, _, T_audio = audio_tensor.shape

        # 2) æ ¹æ® backend æå– latent
        if self.backend == "stablecodec" and self._sc is not None:
            # StableCodec.encode è¿”å› (pre_bottleneck_latents, tokens)
            # latents: [B, H, S]ï¼ŒS â‰ˆ T_audio / hop_size
            latents, _tokens = self._sc.encode(  # type: ignore
                audio_tensor,
                posthoc_bottleneck=posthoc_bottleneck,
            )
            # [B, H, S] -> [B, S, H]
            latent_bts = latents.transpose(1, 2).contiguous()
            self.teacher_dim = latent_bts.size(-1)
        else:
            # Mock encoder: [B,1,T] -> [B, D_mock, S_mock]
            feats = self.mock_encoder(audio_tensor)  # [B, D, S]
            latent_bts = feats.transpose(1, 2).contiguous()  # [B, S, D]

        # 3) å¯é€‰ï¼šå¯¹é½åˆ° FARGAN å¸§ç‡ï¼ˆçº¦ 100Hzï¼‰
        if align_to_fargan and self.fargan_frame_rate > 0:
            # target_frames â‰ˆ T_audio / (sample_rate / fargan_frame_rate)
            frames_per_second = self.fargan_frame_rate
            target_T = int(round(T_audio / self.sample_rate * frames_per_second))
            if target_T <= 1:
                return latent_bts
            latent_btC = latent_bts.transpose(1, 2)  # [B,C,S]
            latent_up = F.interpolate(
                latent_btC,
                size=target_T,
                mode="linear",
                align_corners=False,
            )
            latent_bts = latent_up.transpose(1, 2).contiguous()

        return latent_bts

    @torch.no_grad()
    def get_latent_stats(self, latent: torch.Tensor) -> Dict[str, float]:
        """åˆ†æ latent ç»Ÿè®¡ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•/ç›‘æ§ã€‚"""
        return {
            "mean": float(latent.mean().item()),
            "std": float(latent.std().item()),
            "min": float(latent.min().item()),
            "max": float(latent.max().item()),
            "norm": float(latent.norm().item()),
        }


class PrecomputedStableCodecTeacher(nn.Module):
    """
    é¢„è®¡ç®—ç‰ˆStableCodec Teacher

    ä½¿ç”¨ç¦»çº¿é¢„è®¡ç®—çš„StableCodec latentï¼Œé¿å…è¿è¡Œæ—¶ä¾èµ–
    é€‚ç”¨äºè®­ç»ƒæ—¶å·²ç»æå–å¥½teacher latentçš„åœºæ™¯
    """

    def __init__(self,
                 teacher_dim: int = 6,
                 cache_dir: str = './teacher_cache'):
        super().__init__()

        self.teacher_dim = teacher_dim
        self.cache_dir = cache_dir
        self.latent_cache = {}

        os.makedirs(cache_dir, exist_ok=True)

    def cache_latent(self, audio_key: str, latent: torch.Tensor):
        """ç¼“å­˜teacher latent"""
        cache_path = os.path.join(self.cache_dir, f"{audio_key}.pt")
        torch.save(latent.cpu(), cache_path)
        self.latent_cache[audio_key] = latent

    def load_latent(self, audio_key: str) -> Optional[torch.Tensor]:
        """åŠ è½½ç¼“å­˜çš„teacher latent"""
        if audio_key in self.latent_cache:
            return self.latent_cache[audio_key]

        cache_path = os.path.join(self.cache_dir, f"{audio_key}.pt")
        if os.path.exists(cache_path):
            latent = torch.load(cache_path, map_location='cpu')
            self.latent_cache[audio_key] = latent
            return latent

        return None

    def encode_latent(self, audio_key: str) -> torch.Tensor:
        """é€šè¿‡audio_keyè·å–é¢„è®¡ç®—çš„latent"""
        latent = self.load_latent(audio_key)
        if latent is None:
            raise ValueError(f"æœªæ‰¾åˆ°audio_key '{audio_key}' çš„teacher latent")
        return latent


class StableCodecDistillationLoss(nn.Module):
    """
    StableCodecè’¸é¦æŸå¤±

    è®¡ç®—Hash bottleneckè¾“å‡ºä¸StableCodec teacherä¹‹é—´çš„è’¸é¦æŸå¤±
    """

    def __init__(self,
                 temperature: float = 1.0,
                 feature_weight: float = 1.0,
                 cosine_weight: float = 0.5,
                 contrastive_weight: float = 0.3):
        super().__init__()

        self.temperature = temperature
        self.feature_weight = feature_weight
        self.cosine_weight = cosine_weight
        self.contrastive_weight = contrastive_weight

    def forward(self,
                student_features: torch.Tensor,
                teacher_features: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—è’¸é¦æŸå¤±

        Args:
            student_features: Hash decoderè¾“å‡º [B, T, D_s]
            teacher_features: StableCodec latent [B, T, D_t]

        Returns:
            æŸå¤±å­—å…¸
        """
        # å¦‚æœç»´åº¦ä¸åŒ¹é…ï¼Œéœ€è¦æŠ•å½±
        if student_features.size(-1) != teacher_features.size(-1):
            # ç®€å•çº¿æ€§æŠ•å½± (å®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å¯¹é½)
            if not hasattr(self, 'projection'):
                self.projection = nn.Linear(
                    student_features.size(-1),
                    teacher_features.size(-1)
                ).to(student_features.device)
            student_projected = self.projection(student_features)
        else:
            student_projected = student_features

        losses = {}

        # 1. ç‰¹å¾é‡å»ºæŸå¤±
        losses['feature_mse'] = F.mse_loss(student_projected, teacher_features)

        # 2. ä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±
        cos_sim = F.cosine_similarity(student_projected, teacher_features, dim=-1)
        losses['cosine_loss'] = 1 - cos_sim.mean()

        # 3. å¯¹æ¯”å­¦ä¹ æŸå¤± (æ—¶åºä¸Šä¸‹æ–‡)
        if teacher_features.size(1) > 1:
            # æ­£æ ·æœ¬ï¼šåŒä¸€æ—¶åˆ»
            pos_sim = F.cosine_similarity(student_projected, teacher_features, dim=-1)

            # è´Ÿæ ·æœ¬ï¼šæ—¶ç§»
            neg_teacher = torch.roll(teacher_features, shifts=1, dims=1)
            neg_sim = F.cosine_similarity(student_projected, neg_teacher, dim=-1)

            logits = torch.stack([pos_sim, neg_sim], dim=-1) / self.temperature
            targets = torch.zeros(logits.size(0), logits.size(1),
                                dtype=torch.long, device=logits.device)

            losses['contrastive'] = F.cross_entropy(
                logits.view(-1, 2), targets.view(-1)
            )
        else:
            losses['contrastive'] = torch.tensor(0.0, device=student_features.device)

        # æ€»æŸå¤±
        losses['total'] = (
            self.feature_weight * losses['feature_mse'] +
            self.cosine_weight * losses['cosine_loss'] +
            self.contrastive_weight * losses['contrastive']
        )

        return losses


if __name__ == "__main__":
    # ç®€å•è‡ªæµ‹ï¼šåœ¨å½“å‰ç¯å¢ƒä¸‹æ£€æŸ¥ StableCodecTeacher æ˜¯å¦èƒ½å·¥ä½œ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("ğŸ§ª æµ‹è¯• StableCodecTeacher ...")

    # æ„é€  teacherï¼ˆå¯èƒ½ä½¿ç”¨ StableCodecï¼Œä¹Ÿå¯èƒ½å›é€€åˆ° mockï¼‰
    teacher = StableCodecTeacher(device=device)

    # æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®ï¼ˆ2 ç§’ 16kHz å™ªå£°ï¼‰
    sample_rate = 16000
    duration = 2.0
    audio = torch.randn(1, sample_rate * int(duration), device=device)

    latent = teacher.encode_latent(audio, align_to_fargan=True)
    print(f"è¾“å…¥éŸ³é¢‘: {audio.shape}, è¾“å‡º latent: {latent.shape}")
    print("Latent ç»Ÿè®¡:", teacher.get_latent_stats(latent))

    # è’¸é¦æŸå¤± quick check
    distill = StableCodecDistillationLoss().to(device)
    student = torch.randn_like(latent)
    losses = distill(student, latent)
    print("è’¸é¦æŸå¤±ç¤ºä¾‹:", {k: float(v.item()) for k, v in losses.items()})

    print("âœ… StableCodecTeacher è‡ªæµ‹å®Œæˆã€‚")
