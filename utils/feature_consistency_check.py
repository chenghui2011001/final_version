#!/usr/bin/env python3
"""
ç‰¹å¾ä¸€è‡´æ€§æ£€æŸ¥è„šæœ¬
éªŒè¯extract_features_48_lpcnet_style.pyä¸feature_spec.pyçš„å®Œå…¨ä¸€è‡´æ€§
"""

import numpy as np
import torch
from pathlib import Path
from feature_spec import get_default_feature_spec
import argparse


def check_feature_layout_consistency():
    """æ£€æŸ¥ç‰¹å¾å¸ƒå±€å®šä¹‰çš„ä¸€è‡´æ€§"""
    print("ğŸ” æ£€æŸ¥ç‰¹å¾å¸ƒå±€ä¸€è‡´æ€§...")

    spec = get_default_feature_spec()

    # éªŒè¯æ€»ç»´åº¦
    assert spec.total_dim == 48, f"æ€»ç»´åº¦åº”ä¸º48ï¼Œå®é™…ä¸º{spec.total_dim}"

    # éªŒè¯å„å­ç‰¹å¾ç»´åº¦
    expected_dims = {
        'ceps': 20,      # [0:19] -> 20ç»´
        'f0': 1,         # [20] -> 1ç»´
        'voicing': 1,    # [21] -> 1ç»´
        'enhanced': 6,   # [22:27] -> 6ç»´
        'lpc': 16,       # [28:43] -> 16ç»´
        'prosodic': 4    # [44:47] -> 4ç»´
    }

    for feature_name, expected_dim in expected_dims.items():
        actual_dim = spec.get_feature_dims(feature_name)
        assert actual_dim == expected_dim, f"{feature_name}ç»´åº¦ä¸åŒ¹é…: æœŸæœ›{expected_dim}, å®é™…{actual_dim}"
        print(f"  âœ… {feature_name}: {actual_dim}ç»´")

    # éªŒè¯èŒƒå›´è¿ç»­æ€§
    ranges = [
        spec.ceps_range,      # (0, 20)
        spec.f0_range,        # (20, 21)
        spec.voicing_range,   # (21, 22)
        spec.enhanced_range,  # (22, 28)
        spec.lpc_range,       # (28, 44)
        spec.prosodic_range   # (44, 48)
    ]

    expected_start = 0
    for i, (start, end) in enumerate(ranges):
        assert start == expected_start, f"èŒƒå›´{i}å¼€å§‹ä½ç½®é”™è¯¯: æœŸæœ›{expected_start}, å®é™…{start}"
        expected_start = end

    assert expected_start == 48, f"æœ€ç»ˆä½ç½®åº”ä¸º48ï¼Œå®é™…ä¸º{expected_start}"

    print("  âœ… ç‰¹å¾å¸ƒå±€å®Œå…¨ä¸€è‡´")
    return True


def check_feature_extraction_consistency(features_data: np.ndarray):
    """æ£€æŸ¥ç‰¹å¾æå–çš„ä¸€è‡´æ€§"""
    print("ğŸ” æ£€æŸ¥ç‰¹å¾æå–ä¸€è‡´æ€§...")

    spec = get_default_feature_spec()

    # è½¬æ¢ä¸ºtorchå¼ é‡è¿›è¡Œæµ‹è¯•
    features = torch.from_numpy(features_data).float()
    B, T, D = features.shape

    if D != 48:
        print(f"âŒ ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: æœŸæœ›48, å®é™…{D}")
        return False

    # æå–å„å­ç‰¹å¾
    ceps = spec.extract_feature(features, 'ceps')
    f0 = spec.extract_feature(features, 'f0')
    voicing = spec.extract_feature(features, 'voicing')
    enhanced = spec.extract_feature(features, 'enhanced')
    lpc = spec.extract_feature(features, 'lpc')
    prosodic = spec.extract_feature(features, 'prosodic')

    # é‡æ–°æ‹¼æ¥
    reconstructed = torch.cat([ceps, f0, voicing, enhanced, lpc, prosodic], dim=-1)

    # éªŒè¯æ‹¼æ¥ç»“æœä¸åŸå§‹ç‰¹å¾å®Œå…¨ä¸€è‡´
    max_diff = torch.max(torch.abs(features - reconstructed)).item()

    if max_diff > 1e-6:
        print(f"âŒ ç‰¹å¾æ‹¼æ¥ä¸ä¸€è‡´ï¼Œæœ€å¤§å·®å¼‚: {max_diff}")
        return False

    print(f"  âœ… ç‰¹å¾æå–ä¸æ‹¼æ¥å®Œå…¨ä¸€è‡´ (æœ€å¤§å·®å¼‚: {max_diff:.2e})")

    # æ‰“å°å„ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    print("  ğŸ“Š å„ç‰¹å¾ç»Ÿè®¡:")
    for name, feat in [('ceps', ceps), ('f0', f0), ('voicing', voicing),
                      ('enhanced', enhanced), ('lpc', lpc), ('prosodic', prosodic)]:
        mean = feat.mean().item()
        std = feat.std().item()
        min_val = feat.min().item()
        max_val = feat.max().item()
        print(f"    {name:>8}: mean={mean:7.3f}, std={std:6.3f}, range=[{min_val:7.3f}, {max_val:7.3f}]")

    return True


def check_normalization_consistency(features_data: np.ndarray):
    """æ£€æŸ¥å½’ä¸€åŒ–ä¸€è‡´æ€§"""
    print("ğŸ” æ£€æŸ¥å½’ä¸€åŒ–ä¸€è‡´æ€§...")

    spec = get_default_feature_spec()
    features = torch.from_numpy(features_data).float()

    # åº”ç”¨LPCNeté£æ ¼å½’ä¸€åŒ–
    normalized = spec.apply_lpcnet_normalization(features)

    # æ£€æŸ¥å„ç‰¹å¾çš„å½’ä¸€åŒ–ç»“æœ
    f0_norm = spec.extract_feature(normalized, 'f0')
    voicing_norm = spec.extract_feature(normalized, 'voicing')

    # F0åº”è¯¥åœ¨[0,1]èŒƒå›´å†…
    f0_min, f0_max = f0_norm.min().item(), f0_norm.max().item()
    print(f"  F0å½’ä¸€åŒ–èŒƒå›´: [{f0_min:.3f}, {f0_max:.3f}]")

    # Voicingåº”è¯¥æ˜¯0/1å€¼
    voicing_unique = torch.unique(voicing_norm).tolist()
    print(f"  Voicingå”¯ä¸€å€¼: {voicing_unique}")

    # CEPSåº”è¯¥æ¥è¿‘é›¶å‡å€¼å•ä½æ–¹å·®
    ceps_norm = spec.extract_feature(normalized, 'ceps')
    ceps_mean = ceps_norm.mean().item()
    ceps_std = ceps_norm.std().item()
    print(f"  CEPSå½’ä¸€åŒ–: mean={ceps_mean:.3f}, std={ceps_std:.3f}")

    print("  âœ… å½’ä¸€åŒ–æ£€æŸ¥å®Œæˆ")
    return True


def main():
    parser = argparse.ArgumentParser(description='ç‰¹å¾ä¸€è‡´æ€§æ£€æŸ¥')
    parser.add_argument('--features-file', type=str, default=None,
                       help='48ç»´ç‰¹å¾æ–‡ä»¶è·¯å¾„(.f32)')
    parser.add_argument('--sample-frames', type=int, default=1000,
                       help='é‡‡æ ·å¸§æ•°è¿›è¡Œæ£€æŸ¥')

    args = parser.parse_args()

    print("ğŸ§ª ç‰¹å¾ä¸€è‡´æ€§æ£€æŸ¥å¼€å§‹")
    print("=" * 50)

    # æ£€æŸ¥ç‰¹å¾å¸ƒå±€ä¸€è‡´æ€§
    try:
        check_feature_layout_consistency()
    except Exception as e:
        print(f"âŒ ç‰¹å¾å¸ƒå±€æ£€æŸ¥å¤±è´¥: {e}")
        return False

    # å¦‚æœæä¾›äº†ç‰¹å¾æ–‡ä»¶ï¼Œè¿›è¡Œå®é™…æ•°æ®æ£€æŸ¥
    if args.features_file:
        features_path = Path(args.features_file)
        if not features_path.exists():
            print(f"âŒ ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {features_path}")
            return False

        print(f"ğŸ“ åŠ è½½ç‰¹å¾æ–‡ä»¶: {features_path}")

        # åŠ è½½ç‰¹å¾æ•°æ®
        features_data = np.fromfile(features_path, dtype=np.float32)
        total_frames = len(features_data) // 48
        features_data = features_data.reshape(-1, 48)

        print(f"  æ€»å¸§æ•°: {total_frames:,}")

        # é‡‡æ ·è¿›è¡Œæ£€æŸ¥
        sample_frames = min(args.sample_frames, total_frames)
        if sample_frames < total_frames:
            indices = np.random.choice(total_frames, sample_frames, replace=False)
            sample_data = features_data[indices]
        else:
            sample_data = features_data

        # é‡æ–°æ•´å½¢ä¸º[B, T, D]æ ¼å¼
        sample_data = sample_data.reshape(1, -1, 48)

        print(f"  é‡‡æ ·æ£€æŸ¥: {sample_data.shape[1]}å¸§")

        # æ£€æŸ¥ç‰¹å¾æå–ä¸€è‡´æ€§
        try:
            check_feature_extraction_consistency(sample_data)
        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–æ£€æŸ¥å¤±è´¥: {e}")
            return False

        # æ£€æŸ¥å½’ä¸€åŒ–ä¸€è‡´æ€§
        try:
            check_normalization_consistency(sample_data)
        except Exception as e:
            print(f"âŒ å½’ä¸€åŒ–æ£€æŸ¥å¤±è´¥: {e}")
            return False

    print("=" * 50)
    print("ğŸ‰ æ‰€æœ‰ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ï¼")
    return True


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤ºç”¨æ³•"""
    print("ğŸ® å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼")

    # ç”Ÿæˆéšæœºç‰¹å¾æ•°æ®
    features = torch.randn(2, 100, 48)  # [B=2, T=100, D=48]

    spec = get_default_feature_spec()

    # æ‰“å°ç‰¹å¾å¸ƒå±€
    spec.print_feature_layout()

    # æ¼”ç¤ºç‰¹å¾æå–
    print("\nğŸ“Š ç‰¹å¾æå–æ¼”ç¤º:")
    for feature_name in ['ceps', 'f0', 'voicing', 'enhanced', 'lpc', 'prosodic']:
        feat = spec.extract_feature(features, feature_name)
        print(f"  {feature_name:>8}: {feat.shape}")

    # æ¼”ç¤ºå½’ä¸€åŒ–
    normalized = spec.apply_lpcnet_normalization(features)
    print(f"\nğŸ”„ å½’ä¸€åŒ–ç»“æœ: {normalized.shape}")

    return check_feature_extraction_consistency(features.numpy())


if __name__ == "__main__":
    import sys

    if len(sys.argv) == 1:
        # æ— å‚æ•°æ—¶è¿è¡Œæ¼”ç¤º
        quick_demo()
    else:
        # æœ‰å‚æ•°æ—¶è¿è¡Œå®Œæ•´æ£€æŸ¥
        main()